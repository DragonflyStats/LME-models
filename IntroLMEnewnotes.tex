% http://www.math.ku.dk/~erhansen/web/stat1/pinheiro.pdf  -IMPORTANT
\documentclass[12pt, a4paper]{article}
\usepackage{natbib}
\usepackage{vmargin}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{subfigure}
\usepackage{amsbsy}
\usepackage{amsthm, amsmath}
%\usepackage[dvips]{graphicx}
\bibliographystyle{chicago}
\renewcommand{\baselinestretch}{1.4}

% left top textwidth textheight headheight % headsep footheight footskip
\setmargins{3.0cm}{2.5cm}{15.5 cm}{23.5cm}{0.5cm}{0cm}{1cm}{1cm}

\pagenumbering{arabic}


\begin{document}
\author{Kevin O'Brien}
\title{Introduction to LME Models}
\begin{document}
	\newpage
	\section{Linear Mixed Effects Models}
	
	% \subsection{What are LME Models?}
	
	% \subsection{Laird-Ware Notation}
	
	\subsection{Why use LMEs for Method Comparison?}
	
	
	
	
	The well-known ``Limits of Agreement", as developed by Bland and Altman (1986) are easily computable using the LME framework, proposed by Roy. While we will not be considering this analysis, a demonstration will be provided in the example.
	
	Further to this, Roy(2009) demonstrates an suite of tests that can be used to determine how well two methods of measurement, in the presence of repeated measures, agree with each other.
	
	\begin{itemize}\itemsep0.5cm
		\item No Significant inter-method bias
		\item No difference in the between-subject variabilities of the two methods
		\item No difference in the within-subject variabilities of the two methods
	\end{itemize}
\newpage	

\begin{enumerate}
\item Classical models
\item Grouped data sets
\item variance components
\begin{enumerate}
\item Fixed effects
\item Random effects
\end{enumerate}
\end{enumerate}

\section{Classical Models}
%http://www.spss.ch/upload/1126184451_Linear%20Mixed%20Effects%20Modeling%20in%20SPSS.pdf

A fitted model has the form $y\;=\;X\beta+\varepsilon$, where $y$ is a vector of responses, $X$ is the fixed-effects design matrix, $\beta$ is a 
vector of fixed-effects parameters and $\boldsymbol{\varepsilon}}$ is a vector of residual errors.

%LAter

\subsection{With non-iid residual errors}
%spss.ch
%Growth Data Set?
The assumption may be violated in some situations. This often happens when repeated measurements are made on each 
subject. In the \textit{growth} study dataset, for example, the response variable of each subject is measured at various ages. We 
may suspect that error terms within a subject are correlated. A reasonable choice of the residual error covariance will therefore 
be a block diagonal matrix, where each block is a first-order autoregressive (AR1) covariance matrix.




