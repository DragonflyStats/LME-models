\documentclass[12pt, a4paper]{article}
\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsthm}
%\usepackage[dvips]{graphicx}
\usepackage{natbib}
\bibliographystyle{chicago}
\usepackage{vmargin}
% left top textwidth textheight headheight
% headsep footheight footskip
\setmargins{3.0cm}{2.5cm}{15.5 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}
\renewcommand{\baselinestretch}{1.5}
\pagenumbering{arabic}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{ill}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{axiom}{Axiom}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{notation}{Notation}
\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\renewcommand{\thenotation}{}
\renewcommand{\thetable}{\thesection.\arabic{table}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\title{Research notes: linear mixed effects models}
\author{ } \date{ }


\begin{document}
	\author{Kevin O'Brien}
	\title{LME Estimation and Algorithms}
	
	\tableofcontents \setcounter{tocdepth}{2}
	%------------------------------------------------- MLE Algorithms %
	
	
\section{LME Introduction}



Henderson [1984a] shows that the solution to the mixed model equations
\begin{equation}
	\left(
	\begin{array}{cc}
		X^{\prime}R^{-1}X & X^{\prime}R^{-1}Z \\
		Z^{\prime}R^{-1}X & Z^{\prime}R^{-1}Z + G^{-1}\\
	\end{array}
	\right)\left(
	\begin{array}{c}
		\boldsymbol{\beta} \\
		\boldsymbol{b} \\
	\end{array}
	\right) = \left(
	\begin{array}{c}
		X^{\prime}R^{-1}y \\
		Z^{\prime}R^{-1}y \\
	\end{array}
	\right)
\end{equation}
gives a solution for which the estimate $\boldsymbol{b}$ of the fixed effects is equal to that obtained by generalized least squares.

\begin{equation}
	\hat{\beta} = (\boldsymbol{X^{\prime}}\boldsymbol{V}^{-1}\boldsymbol{X})^{-1}\boldsymbol{X^{\prime}}\boldsymbol{V}^{-1}\boldsymbol{y}
\end{equation}

\citet{Henderson63} showed that
the BLUP of $\boldsymbol{b}$ is

\begin{equation}
	\boldsymbol{\hat{b}} = (\boldsymbol{D}\boldsymbol{Z}^{\prime}\boldsymbol{V})(\boldsymbol{y} - \boldsymbol{X}\hat{\beta})
\end{equation}


%------------------------------------------------------------------------------------%

\subsubsection{Henderson's equations}
Because of the dimensionality of V (i.e. $n \times n$) computing the inverse of V can be difficult. As a way around the this problem \citet{Henderson53, Henderson59,Henderson63,Henderson73,Henderson84a} offered a more simpler approach of jointly estimating $\hat{\beta}$ and $\hat{b}$.
\cite{Henderson:1950} made the (ad-hoc) distributional assumptions $y|b \sim \mathrm{N} (X \beta + Zb, \Sigma)$ and $b \sim \mathrm{N}(0,D),$ and proceeded to maximize the joint density of $y$ and $b$
\begin{equation}
	\left|
	\pmatrix{
		D & 0 \cr
		0 & \Sigma }
	\right|^{-\frac{1}{2}}
	\exp
	\left\{ -\frac{1}{2}
	\pmatrix{
		b \cr
		y - X \beta -Zb
	}^\prime
	\pmatrix{
		D & 0 \cr
		0 & \Sigma }^{-1}
	\pmatrix{
		b \cr
		y - X \beta -Zb
	}
	\right\},
	\label{u&beta:JointDensity}
\end{equation}
with respect to $\beta$ and $b,$ which ultimately requires minimizing the criterion
\begin{equation}
	(y - X \beta -Zb)'\Sigma^{-1}(y - X \beta -Zb) + b^\prime D^{-1}b.
	\label{Henderson:Criterion}
\end{equation}
This leads to the mixed model equations
\begin{equation}
	\pmatrix{
		X^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}Z
		\cr
		Z^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}X + D^{-1}
	}
	\pmatrix{
		\beta \cr
		b
	}
	=
	\pmatrix{
		X^\prime\Sigma^{-1}y \cr
		Z^\prime\Sigma^{-1}y
	}.
	\label{Henderson:Equations}
\end{equation}
Using these equations, obtaining the estimates requires the inversion of a matrix
of dimension $p+q \times p+q$, considerably smaller in size than $V$. \citet{Henderson1963} shows that these mixed model equations do not depend on normality and that $\hat{\beta}$ and $\hat{b}$ are the BLUE and BLUP under general conditions, provided $D$ and $\Sigma$ are known.

\cite{Robi:BLUP:1991} points out that although \cite{Henderson:1950} initially referred to the estimates $\hat{\beta}$ and $\hat{b}$ from (\ref{Henderson:Equations}) as ``joint maximum likelihood estimates", \cite{Henderson:1973} later advised that these estimates should not be referred to as ``maximum likelihood" as the function being maximized in (\ref{Henderson:Criterion}) is a joint density rather than a likelihood function. \cite{Lee:Neld:Pawi:2006} remarks that it is clear that Henderson used joint estimation for computational purposes, without recognizing the theoretical implications.


\subsubsection*{Henderson's equations}

\cite{Henderson:1950} made the (ad-hoc) distributional assumptions $y|b \sim \mathrm{N} (X \beta + Zb, \Sigma)$ and $b \sim \mathrm{N}(0,D),$ and proceeded to maximize the joint density of $y$ and $b$
\begin{equation}
	\left|
	\pmatrix{
		D & 0 \cr
		0 & \Sigma }
	\right|^{-\frac{1}{2}}
	\exp
	\left\{ -\frac{1}{2}
	\pmatrix{
		b \cr
		y - X \beta -Zb
	}^\prime
	\pmatrix{
		D & 0 \cr
		0 & \Sigma }^{-1}
	\pmatrix{
		b \cr
		y - X \beta -Zb
	}
	\right\},
	\label{u&beta:JointDensity}
\end{equation}
with respect to $\beta$ and $b,$ which ultimately requires minimizing the criterion
\begin{equation}
	(y - X \beta -Zb)'\Sigma^{-1}(y - X \beta -Zb) + b^\prime D^{-1}b. 
	\label{Henderson:Criterion}
\end{equation}
This leads to the solutions
\begin{equation}
	\pmatrix{
		X^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}Z
		\cr
		Z^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}X + D^{-1}
	}
	\pmatrix{
		\beta \cr
		b
	}
	=
	\pmatrix{
		X^\prime\Sigma^{-1}y \cr
		Z^\prime\Sigma^{-1}y
	}.
	\label{Henderson:Equations}
\end{equation}
\cite{Robi:BLUP:1991} points out that although \cite{Henderson:1950} initially referred to the estimates $\hat{\beta}$ and $\hat{b}$ from (\ref{Henderson:Equations}) as ``joint maximum likelihood estimates" \cite{Henderson:1973} later advised that these estimates should not be referred to as ``maximum likelihood" as the function being maximized in (\ref{Henderson:Criterion}) is a joint density rather than a likelihood function.


\subsubsection{Henderson's equations}
Because of the dimensionality of V (i.e. $n \times n$) computing the inverse of V can be difficult. As a way around the this problem \citet{Henderson53, Henderson59,Henderson63,Henderson73,Henderson84a} offered a more simpler approach of jointly estimating $\hat{\beta}$ and $\hat{b}$.
\cite{Henderson:1950} made the (ad-hoc) distributional assumptions $y|b \sim \mathrm{N} (X \beta + Zb, \Sigma)$ and $b \sim \mathrm{N}(0,D),$ and proceeded to maximize the joint density of $y$ and $b$
\begin{equation}
\left|
\pmatrix{
  D & 0 \cr
  0 & \Sigma }
  \right|^{-\frac{1}{2}}
\exp
\left\{ -\frac{1}{2}
\pmatrix{
  b \cr
  y - X \beta -Zb
  }^\prime
\pmatrix{
  D & 0 \cr
  0 & \Sigma }^{-1}
\pmatrix{
  b \cr
  y - X \beta -Zb
  }
\right\},
\label{u&beta:JointDensity}
\end{equation}
with respect to $\beta$ and $b,$ which ultimately requires minimizing the criterion
\begin{equation}
(y - X \beta -Zb)'\Sigma^{-1}(y - X \beta -Zb) + b^\prime D^{-1}b.
\label{Henderson:Criterion}
\end{equation}
This leads to the mixed model equations
\begin{equation}
\pmatrix{
  X^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}Z
  \cr
  Z^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}X + D^{-1}
  }
\pmatrix{
    \beta \cr
  b
  }
  =
\pmatrix{
  X^\prime\Sigma^{-1}y \cr
  Z^\prime\Sigma^{-1}y
  }.
\label{Henderson:Equations}
\end{equation}
Using these equations, obtaining the estimates requires the inversion of a matrix
of dimension $p+q \times p+q$, considerably smaller in size than $V$. \citet{Henderson1963} shows that these mixed model equations do not depend on normality and that $\hat{\beta}$ and $\hat{b}$ are the BLUE and BLUP under general conditions, provided $D$ and $\Sigma$ are known.

\cite{Robi:BLUP:1991} points out that although \cite{Henderson:1950} initially referred to the estimates $\hat{\beta}$ and $\hat{b}$ from (\ref{Henderson:Equations}) as ``joint maximum likelihood estimates", \cite{Henderson:1973} later advised that these estimates should not be referred to as ``maximum likelihood" as the function being maximized in (\ref{Henderson:Criterion}) is a joint density rather than a likelihood function. \cite{Lee:Neld:Pawi:2006} remarks that it is clear that Henderson used joint estimation for computational purposes, without recognizing the theoretical implications.

\end{document}
