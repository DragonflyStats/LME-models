\documentclass[12pt, a4paper]{article}
\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsthm}
%\usepackage[dvips]{graphicx}
\usepackage{natbib}
\bibliographystyle{chicago}
\usepackage{vmargin}
% left top textwidth textheight headheight
% headsep footheight footskip
\setmargins{3.0cm}{2.5cm}{15.5 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}
\renewcommand{\baselinestretch}{1.5}
\pagenumbering{arabic}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{ill}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{axiom}{Axiom}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{notation}{Notation}
\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\renewcommand{\thenotation}{}
\renewcommand{\thetable}{\thesection.\arabic{table}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\title{Research notes: linear mixed effects models}
\author{ } \date{ }


\begin{document}
\author{Kevin O'Brien}
\title{Mixed Models for Method Comparison Studies}

\chapter{Linear Mixed Effects Models}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% http://www.artifex.org/~meiercl/R_statistics_guide.pdf
These models are used when there are both fixed and random effects that need to be incorporated into a model.

Fixed effects usually correspond to experimental treatments for which one has data for the entire population of samples corresponding to that treatment.

Random effects,on the other hand, are assigned in the case where we have measurements on a group of samples, and those
samples are taken from some larger sample pool, and are presumed to be representative.

As such, linear mixed effects models treat the error for fixed effects differently than the error for random effects.

%----------------------------------------------------------------------------------------%
\section{Applications}
So-called mixed-effect models (or just mixed models) include
additional random-effect terms, and are often appropriate for
representing clustered, and therefore dependent, data Â– arising,
for example, when data are collected hierarchically, when
observations are taken on related individuals (such as siblings),
or when data are gathered over time on the same individuals.


\section{Distinction between Classical Models and Mixed Models}
\citet{Demi} discusses the inadequacy of `classical models' in
analysing such data types, with particular reference to the simple
linear model. The simple linear model is a well known statistical
methodology that describes the relationship between dependent
variables $Y$ and an independent predictor variable $X$. Where
$Y={y_{1},y_{2},..y_{k}..y_{n}}$ and
$X={x_{1},x_{2},..x_{k}..x_{n}}$, an intercept $\alpha$ and slope
$\beta$ are estimated such that the error terms associated with
each observation $y_{i}$ is minimized.

\begin{equation}
y_{k} = \alpha + \beta x_{k}+ \epsilon_{k}
\end{equation}
In classical statistics a typical assumption is that observations
are drawn from the same general population, are independent and
identically distributed \citep{Demi}. Consequently there is no way
to account for the grouped nature of data sets described
previously, and so there lies the possibility of observations
being treated as independent measurements. \citet[pg.3]{Demi}
gives a very informative example wherein a classical approach is
compared to an approach that does account for grouping. The
conclusion to be drawn from Demidenko's example is that failure to
account for grouping leads to an incorrect conclusion about the
data. The approach recommended is known as `mixed models' and
shall be introduced presently.

section{Fixed Effects and Random Effects Models}
Before proceeding to a description of mixed models, an
introduction to fixed effects and random effects models is
required. This section follows on from the discussion of
measurement error models in the last chapter.

%A model should be regarded as mathematical description of
%observations with respect to the effect of a number of factors,
%and error terms.





\section{Fixed Effects and Random Effects Models}
Before proceeding to a description of mixed models, an
introduction to fixed effects and random effects models is
required. This section follows on from the discussion of
measurement error models in the last chapter.

%A model should be regarded as mathematical description of
%observations with respect to the effect of a number of factors,
%and error terms.



\section{Mixed Models}

%\citet{BrownPrescott} defines random effects as realizations of
%samples from a normal distribution with mean equal to zero.

All models are characterized by the mean $\alpha$ and the error
terms. In addition to these terms, any model described so far will
have either random effects terms or fixed effects terms and
accordingly are referred to as random or fixed models. Models that
have both fixed effects terms and random effects terms are known
as 'mixed effects models'. Once the theory underlying fixed and
random effects models has been fully understood, the progression
to understanding mixed models is very simple.

Elaborating on the original mice litter example, the six litters
by each mouse were fed according to three different dietary
treatments \citep{Searle}. Therefore a fixed effect $\phi_{j}$ has
been added to the model, which is now formulated as follows;
\begin{equation}
y_{ij} = \mu + \delta_{i} + \phi_{j} + \gamma_{ij} +
\epsilon_{ijk}
\end{equation}
As before, an interaction effect $\gamma_{ij}$ must also be added
to the model. In cases where the interaction term describes the
combined effect of fixed and random components, it should be
treated as random effect. The variance of the above model is
composed of the $\sigma^{2}_{\delta}$, $\sigma^{2}_{\gamma}$ and
$\sigma^{2}_{\epsilon}$ .


It may be shown that the interaction factors make no contribution
to the outcome, i.e $\gamma_{ij}$ is consistently calculated as
zero. Considering the skin tumour example, a person's age would
bear no relation to their gender and hence there would be
plausible interaction between the two factors. Indeed , in keeping
with the `Law of Parsimony', factors should be specified such that
each would convey separate information. However, interaction terms
are extant when the model specifies repeated observations, as
there is necessarily a relationship between observations from the
same subject. Importantly, interaction effects, being random
effects, are attended by variance component terms and therefore
also contribute to the overall variance of the model.

\citet{Searle} gives a mixed effects model formulation for the
Grubbs artillery study. $y_{ij}$ is the muzzle velocity of the
$i$th shell, as measured by the $j$th chronometer.
\begin{equation}
y_{ij} = \mu + \alpha_{i} + \beta_{j}  + \epsilon_{ij}
\end{equation}
In this formulation $\alpha_{i}$ is the random effect of round
$i$, and the fixed effect component $\beta_{j}$ is the bias in
chronometer $j$. (Also, no interaction term is used).






\subsection{Advantages of Mixed Models}
\citet{BrownPrescott} discusses the  following advantages of using
mixed effects models. In the case of repeated measurements , it is
appropriate to take account of the correlation of each group of
observations. Mixed models lead to more appropriate estimates and
standard errors for fixed effects, particularly in the case of
repeated measures. Analysis using a mixed model is more
appropriate for inference on a hierarchical data. In the case of
unbalanced data, mixed models are more appropriate than other
methodologies.

\citet{Demi} comments that mixed models are the correct approach
for dealing with grouped data. The use of linear mixed effects
models has advanced greatly with increased usage of statistical
software. This author also notes that mixed models are a hybrid of
bayesian and frequentist methodologies and that mixed model
approaches are more flexible than bayesian.


\subsubsection{Unbalanced Data} Unbalanced data refers to situations where these groups are
of different sizes. Mixed Effects Models are suitable for studying
unbalanced data sets. The variance components of random effects
for these set can not be derived using alternative methods such as
ANOVA.

\subsection{Fixed Effects}
\citet{McCullSearle} gives an example of a study where the
observations , occurrences of skin tumours called basal cell
epithelioma, were classified according to `factors', i.e. the
gender, age and exposure to sunshine of the patients. Levels are
the individual classes of each of these factors (e.g. `Male' and
`Female' would be the levels of the factor `Gender'). The
scientific interest lies in examining the extent to which
different factor levels affect the variable of interest. The
effects of a level of a factor are one of two types ; fixed
effects and random effects. Fixed effects describe effects due to
a finite set of levels for a factor (i.e multichotomous factors).
The factors described in the skin tumour example are all fixed
effects factors. Fixed effects models are the cases where only
fixed effects are present, with the exception of random error
terms.

To demonstrate fixed effects model \citet{Searle} describes a
study wherein $24$ plants are divided into four groups of six, and
each group is subjected to its own treatment regime. Three
different fertilizers are used with three of the groups
(treatments $N$,$P$,$K$), while no fertilizer is used on the
fourth group, (i.e. it is a control group denoted as $C$).
\citet{Searle} constructs a model to describe the crop yield
resultant from the experiment.

\begin{equation}
y_{ij} = \mu + \alpha_{i} + e_{ij}
\end{equation}

where $y_{ij}$ is the $j$th plant (i.e. crop yield) on the $i$th
treatment, with $\mu$ as the mean yield, $\alpha_{i}$ is the
effect of each fertilizer treatments (i.e. fixed effects) and
$e_{ij}$ is the error term. The fixed effect for each observation
is an unknown constant that is to be determined from computing the
data.

The $\mu$ term would not
necessarily be present in all formulations. Some authors, such as
\citet{Demi}, may use a single term as equivalent to the $\mu$ and
$\alpha$ terms. (It is customary to centre data prior to using
mixed effects methodologies. Centering means subtracting the mean
of the observations from each observed value, so mean of the
resultant values become zero.)

\subsection{Variance Components}
Each random effect has an associated `variance component' term.
This is a model parameter which quantifies random variation due to
that effect only. Therefore for every observation there are two
sources of variation, random variation and residual variation, and
can be expressed as follows $var(y_{ij})=\sigma^{2}_{p} +
\sigma^{2}$. These variations are known as the variance
components. This is an important difference with fixed effects
models, which is subject to residual variation ( i.e $\sigma^{2}$)
only \citep{BrownPrescott}.

In fixed effects models there is no covariance between any pair of
observations. \citet*{BrownPrescott} shows that, while there is no
covariance between observations from different subjects (i.e the
mice in Searle's example), there exists correlation between
observations from the same subject (i.e. litter weights from the
same mouse are correlated). In this case the covariance is the
subjects variance component (i.e. $\sigma^{2}_{p}$)

\newpage


\subsection{Random Effects}
The random effects model describes the case where there is an
infinite number of levels in a factor. In other words the factor
is a random variable. \citet{Searle} demonstrates this with a
second example; a study of the maternal ability of mice. In this
example 4 female mice , all of the same breed, have 6 litters each
over a period of time. The weights $w_{ij}$ of each litter ($j$)
from each mouse ($i$) were taken to be the proxy for maternal
ability and is formulated as follows;
\begin{equation}
w_{ij} = \mu + \delta_{i} + e_{ij}
\end{equation}

As in the previous exmaple, $\alpha$ is the mean , $e_{ij}$ is the
error term and $\delta_{i}$ is a random effect due to each mouse.
Notably these four mice are considered as a sample of the overall
population of female mice of that breed, consequently an important
characteristic of random effects models is that the $\delta_{i}$
values are a random sample of all $\delta$ terms. Therefore these
random terms can be used for making inferences about populations.
\citep{McCullSearle}.


\subsection{Fixed or Random?}

In the examples discussed so far, it is clear when effects are
fixed or random. In general, however, the difference is not as
clear. \citet{Searle} discusses the decision whether an effect
should be treated as random or fixed, stating that it depends upon
the context of the study, and how the data was gathered. \emph{The
	situation to which the model applies is the deciding factor in
	determining whether effects are fixed or random}.

Referring to the Grubbs data, the shells fired are a random sample
of shells therefore $\alpha_{i}$ components should be considered
random effects. Conversely $\beta_{j}$ are fixed effects
components because the three measurement devices are the only
instruments of interest \citep{Searle}.



\subsection{Matrix Formulation} There are matrix (i.e multivariate)
formulations of both fixed effects models and random effects
models. \citet{BrownPrescott} remarks that the matrix notation
makes the underlying theory of mixed effects models much easier to
work with. The fixed effects models can be specified as follows;

\begin{equation}
\textbf{Y} = \textbf{Xb} + \textbf{e}
\end{equation}

\textbf{Y} is the vector of $n$ observations, with dimension $n
\times 1$. \textbf{b} is a vector of fixed $p$ effects, and has
dimension $p \times 1$. It is composed of coefficients, with the
first element being the population mean. For the skin tumour
example, with the three specified fixed effects, $p=4$. \textbf{X}
is known as the design `matrix', model matrix for fixed effects,
and comprises $0$s or $1$s, depending on whether the relevant
fixed effects have any effect on the observation is question.
\textbf{X} has dimension $n \times p$. \textbf{e} is the vector of
residuals with dimension $n \times 1$.

The random effects models can be specified similarly. \textbf{Z}
is known as the `model matrix for random effects', and also
comprises $0$s or $1$s. It has dimension $n \times q$. \textbf{u}
is a vector of random $q$ effects, and has dimension $q \times 1$.

\begin{equation}
\textbf{Y} = \textbf{Zu} + \textbf{e}
\end{equation}

Again, once the component fixed effects and random effects
components are considered, progression to a mixed model
formulation is a simple step. Further to \citet{LW82}, it is
conventional to formulate a mixed effects model in matrix form as
follows:

\begin{equation}
\textbf{Y} = \textbf{Xb} + \textbf{Zu} + \textbf{e}
\end{equation}

($E(\textbf{u})=0$, $E(\textbf{e})=0 $ and $E(\textbf{y}) =
\textbf{Xb}$)



\subsection{More complex examples}
\citet{Searle} offers elaborations on both examples used so far.
In the case of the fixed effects model, the model can be amended
to take account for different varieties of each plants being
studied. (The groups of six plants are subdivided into three
variety types.) $y_{ijk}$ is the yield of the $k$th plant of the
$j$th variety in the $i$th treatment, and is described as follows;

\begin{equation}
y_{ijk} = \mu + \alpha_{i} + \beta_{j} + \gamma_{ij} + e_{ijk}
\end{equation}
This new formulation includes a fixed effect $\beta_{j}$ to
account for the variety type, and an `interaction effect'
$\gamma_{ij}$. An interaction effect describes the combined
effects of two or more variables on the observation. Similarly the
random effects example is elaborated to account for the effects of
three different technicians. Again there is a random effect
component $\tau$ to account for these technicians, and an
interaction effect $\theta$ to account for the combined effect of
the mice and the technicians.

\begin{equation}
w_{ijk} = \mu + \delta_{i} + \tau_{j} + \theta_{ij} + e_{ijk}
\end{equation}

\section{Using Linear Mixed Effects Models} It is shown that
classical models can give different results to linear mixed
effects models , based on the same data. \citet{Demi} illustrates
this with a comparison of simple regression model of prices
against sales, with a mixed model, that takes groups of data into
account.


\section{Grouped Data Sets}
In modern statistical analysis , data sets have very complex
structures, such as  clustered data, repeated data and
hierarchical data (henceforth referred to as grouped data).

Repeated data considers various observations periodically taken
from the same subjects. `Before and after' measurements, as used
in paired t tests, are a well known example of repeated
measurements. Clustered data is simply the grouping of
observations according to common characteristics. For example, an
study of pupils of a school would account for the fact that they
are grouped according to their classes.

Hierarchical structures organize data into a tree-like structure,
i.e. groups within groups. Using the previous example, the pupils
would be categorized according to their years (i.e the parent
group) and then their classes (i.e the child group). This can be
extended again to multiple schools, where each school would be the
parent group of each year.

An important feature of such data sets is that there is
correlation between observations within each of the groups
\citep{Faraway}. Observations in different groups may be
independent, but any assumption that these observations within the
same group are independent is inappropriate . Consequently
\citet{Demi} states that there is two sources of variations to be
considered, `within groups' and `between groups'.


\newpage
\section{Classical Models}
\citet{Demi} discusses the inadequacy of `classical models' in
analysing such data types, with particular reference to the simple
linear model . The simple linear model is a well known statistical
methodology that describes the relationship between dependent
variables $Y$ and an independent predictor variable $X$. Where
$Y={y_{1},y_{2},..y_{k}..y_{n}}$ and
$X={x_{1},x_{2},..x_{k}..x_{n}}$, an intercept $\alpha$ and slope
$\beta$ are estimated such that the error terms associated with
each observation $y_{i}$ is minimised.

\begin{equation}
y_{k} = \alpha + \beta x_{k}+ \epsilon_{k}
\end{equation}
In classical statistics a typical assumption is that observations
are drawn from the same general population, are independent and
identically distributed \citep{Demi}. Consequently there is no way
to account for the grouped nature of data sets described
previously, and so there lies the possibility of observations
being treated as independent measurements. \citet[pg.3]{Demi}
gives a very informative example wherein a classical approach is
compared to an approach that does account for grouping. The
conclusion to be drawn from Demidenko's example is that failure to
account for grouping leads to an incorrect conclusion about the
data. The approach recommended is known as `mixed models' and
shall be introduced presently.

\chapter{Linear Mixed effects Models}
\section{Linear Mixed effects Models}
A linear mixed effects (LME) model is a statistical model containing both fixed effects and random effects (random effects are also known as variance components). LME models are a generalization of the classical linear model, which contain fixed effects only. When the levels of factors are considered to be sampled from a population,
and each level is not of particular interest, they are considered random quantities with associated variances.
The effects of the levels, as described, are known as random effects. Random effects are represented by unobservable
normally distributed random variables. Conversely fixed effects are considered non-random and the
levels of each factor are of specific interest.
%LME models are useful models when considering repeated measurements or grouped observations.

\citet{Fisher4} introduced variance components models for use in genetical studies. Whereas an estimate for variance must take an non-negative value, an individual variance component, i.e.\ a component of the overall variance, may be negative.

The methodology has developed since, including contributions from
\citet{tippett}, who extend the use of variance components into linear models, and \citet{eisenhart}, who introduced the `mixed model' terminology and formally distinguished between mixed and random effects models. \citet{Henderson:1950} devised a methodology for deriving estimates for both the fixed effects and the random effects, using a set of equations that would become known as `mixed model equations' or `Henderson's equations'.
LME methodology is further enhanced by Henderson's later works \citep{Henderson53, Henderson59,Henderson63,Henderson73,Henderson84a}. The key features of Henderson's work provide the basis for the estimation techniques.

\citet{HartleyRao} demonstrated that unique estimates of the variance components could be obtained using maximum likelihood methods. However these estimates are known to be biased `downwards' (i.e.\ underestimated) , because of the assumption that the fixed estimates are known, rather than being estimated from the data. \citet{PattersonThompson} produced an alternative set of estimates, known as the restricted maximum likelihood (REML) estimates, that do not require the fixed effects to be known. Thusly there is a distinction the REML estimates and the original estimates, now commonly referred to as ML estimates.

\citet{LW82} provides a form of notation for notation for LME models that has since become the standard form, or the basis for more complex formulations. Due to computation complexity, linear mixed effects models have not seen widespread use until many well known statistical software applications began facilitating them. SAS Institute added PROC MIXED to its software suite in 1992 \citep{singer}. \citet{PB} described how to compute LME models in the \texttt{S-plus} environment.

Using Laird-Ware form, the LME model is commonly described in matrix form,
\begin{equation}
y = X\beta + Zb + \epsilon
\label{LW}
\end{equation}

\noindent where $y$ is a vector of $N$ observable random variables, $\beta$ is a vector of $p$ fixed effects, $X$ and $Z$ are $N \times p$ and $N \times q$ known matrices, and $b$ and $\epsilon$  are vectors of $q$ and $N,$ respectively, random effects such that $\mathrm{E}(b)=0, \ \mathrm{E}(\epsilon)=0$
and
\[
\mathrm{var}
\left(
              \begin{array}{c}
                b \\
                \epsilon \\
              \end{array}
            \right)
   =
\left(
         \begin{array}{cc}
           D & 0 \\
           0 & \Sigma \\
         \end{array}
       \right)
\]




where $D$ and $\Sigma$ are positive definite matrices parameterized by an unknown variance component parameter vector $ \theta.$ The variance-covariance matrix for the vector of observations $y$ is given by $V = ZDZ^{\prime}+ \Sigma.$ This implies $y \sim(X\beta, V) = (X\beta,ZDZ^{\prime}+ \Sigma)$. It is worth noting that $V$ is an $n \times n$ matrix, as the dimensionality becomes relevant later on. The notation provided here is generic, and will be adapted to accord with complex formulations that will be encountered in due course.

%\subsection{Likelihood and estimation}

% Likelihood is the hypothetical probability that an event that has already occurred would yield a specific outcome. Likelihood differs from probability in that probability refers to future occurrences, while likelihood refers to past known outcomes.

% The likelihood function ($L(\theta)$)is a fundamental concept in statistical inference. It indicates how likely a particular population is to produce an observed sample. The set of values that maximize the likelihood function are considered to be optimal, and are used as the estimates of the parameters. For computational ease, it is common to use the logarithm of the likelihood function, known simply as the log-likelihood ($\ell(\theta)$).


\subsection{Estimation}
Estimation of LME models involve two complementary estimation issues'; estimating the vectors of the fixed and random effects estimates $\hat{\beta}$ and $\hat{b}$ and estimating the variance covariance matrices $D$ and $\Sigma$.
Inference about fixed effects have become known as `estimates', while inferences about random effects have become known as `predictions'. The most common approach to obtain estimators are Best Linear Unbiased Estimator (BLUE) and Best Linear Unbiased Predictor (BLUP). For an LME model given by (\ref{LW}), the BLUE of $\hat{\beta}$ is given by
\[\hat{\beta} = (X^\prime V^{-1}X)^{-1}X^\prime V^{-1}y,\]whereas the BLUP of $\hat{b}$ is given by
\[\hat{b} = DZ^{\prime} V^{-1} (y-X\hat{\beta}).\]

\subsubsection{Henderson's equations}
Because of the dimensionality of V (i.e. $n \times n$) computing the inverse of V can be difficult. As a way around the this problem \citet{Henderson53, Henderson59,Henderson63,Henderson73,Henderson84a} offered a more simpler approach of jointly estimating $\hat{\beta}$ and $\hat{b}$.
\cite{Henderson:1950} made the (ad-hoc) distributional assumptions $y|b \sim \mathrm{N} (X \beta + Zb, \Sigma)$ and $b \sim \mathrm{N}(0,D),$ and proceeded to maximize the joint density of $y$ and $b$
\begin{equation}
\left|
\begin{array}{cc}
D & 0 \\
0 & \Sigma \\
\end{array}
  \right|^{-\frac{1}{2}}
\exp
\left\{ -\frac{1}{2}
\left(
\begin{array}{c}
                b \\
                y - X \beta -Zb \\
              \end{array}
            \right)^\prime
\left( \begin{array}{cc}
D & 0 \\
0 & \Sigma \\
\end{array}\right)^{-1}
\left(
\begin{array}{c}
                b \\
                y - X \beta -Zb \\
              \end{array}
            \right)
\right\},
\label{u&beta:JointDensity}
\end{equation}
with respect to $\beta$ and $b,$ which ultimately requires minimizing the criterion
\begin{equation}
(y - X \beta -Zb)'\Sigma^{-1}(y - X \beta -Zb) + b^\prime D^{-1}b.
\label{Henderson:Criterion}
\end{equation}
This leads to the mixed model equations
\begin{equation}
\left(\begin{array}{cc}
  X^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}Z
  \\
  Z^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}X + D^{-1}
  \end{array}\right)
\left(\begin{array}{c}
    \beta \\
  b
  \end{array}\right)
  =
\left(\begin{array}{c}
  X^\prime\Sigma^{-1}y \\
  Z^\prime\Sigma^{-1}y
  \end{array}\right).
\label{Henderson:Equations}
\end{equation}
Using these equations, obtaining the estimates requires the inversion of a matrix
of dimension $p+q \times p+q$, considerably smaller in size than $V$. \citet{Henderson1963} shows that these mixed model equations do not depend on normality and that $\hat{\beta}$ and $\hat{b}$ are the BLUE and BLUP under general conditions, provided $D$ and $\Sigma$ are known.

\cite{Robi:BLUP:1991} points out that although \cite{Henderson:1950} initially referred to the estimates $\hat{\beta}$ and $\hat{b}$ from (\ref{Henderson:Equations}) as ``joint maximum likelihood estimates", \cite{Henderson:1973} later advised that these estimates should not be referred to as ``maximum likelihood" as the function being maximized in (\ref{Henderson:Criterion}) is a joint density rather than a likelihood function. \cite{Lee:Neld:Pawi:2006} remarks that it is clear that Henderson used joint estimation for computational purposes, without recognizing the theoretical implications.

\subsubsection{Estimation of the fixed parameters}

The vector $y$ has marginal density $y \sim \mathrm{N}(X \beta,V),$ where $V = \Sigma + ZDZ^\prime$ is specified through the variance component parameters $\theta.$ The log-likelihood of the fixed parameters $(\beta, \theta)$ is
\begin{equation}
\ell (\beta, \theta|y) =
-\frac{1}{2} \log |V| -\frac{1}{2}(y -
X \beta)'V^{-1}(y -
X \beta), \label{Likelihood:MarginalModel}
\end{equation}
and for fixed $\theta$ the estimate $\hat{\beta}$ of $\beta$ is obtained as the solution of
\begin{equation}
(X^\prime V^{-1}X) {\beta} = X^\prime V^{-1}y.
\label{mle:beta:hat}
\end{equation}

Substituting $\hat{\beta}$ from (\ref{mle:beta:hat}) into $\ell(\beta, \theta|y)$ from (\ref{Likelihood:MarginalModel}) returns the \emph{profile} log-likelihood
\begin{eqnarray*}
\ell_P(\theta \mid y) &=& \ell(\hat{\beta}, \theta \mid y) \\
&=& -\frac{1}{2} \log |V| -\frac{1}{2}(y - X \hat{\beta})'V^{-1}(y - X \hat{\beta})
\end{eqnarray*}
of the variance parameter $\theta.$ Estimates of the parameters $\theta$ specifying $V$ can be found by maximizing $\ell_P(\theta \mid y)$ over $\theta.$ These are the ML estimates.

For REML estimation the \emph{restricted} log-likelihood is defined as
\[
\ell_R(\theta \mid y) =
\ell_P(\theta \mid y) -\frac{1}{2} \log |X^\prime VX |.
\]
%\subsubsection{Likelihood estimation techniques}
%Maximum likelihood and restricted maximum likelihood have become the most common strategies
%for estimating the variance component parameter $\theta.$ Maximum likelihood estimation obtains
%parameter estimates by optimizing the likelihood function.
%To obtain ML estimate the likelihood is constructed as a function of the parameters in the specified LME model.
% The maximum likelihood estimates (MLEs) of the parameters are the values of the arguments that maximize the likelihood function.

The REML approach does not base estimates on a maximum likelihood fit of all the information, but instead uses a likelihood function derived from a data set, transformed to remove the irrelevant influences \citep{REMLDefine}.
Restricted maximum likelihood is often preferred to maximum likelihood because REML estimation reduces the bias in the variance component by taking into account the loss of degrees of freedom that results
from estimating the fixed effects in $\boldsymbol{\beta}$. Restricted maximum likelihood also handles high correlations more effectively, and is less sensitive to outliers than maximum likelihood.  The problem with REML for model building is that the likelihoods obtained for different fixed effects are not comparable. Hence it is not valid to compare models with different fixed effects using a likelihood ratio test or AIC when REML is used to
estimate the model. Therefore models derived using ML must be used instead.

\subsubsection{Estimation of the random effects}

The established approach for estimating the random effects is to use the best linear predictor of $b$ from $y,$ which for a given $\beta$ equals $DZ^\prime V^{-1}(y - X \beta).$ In practice $\beta$ is replaced by an estimator such as $\hat{\beta}$ from (\ref{mle:beta:hat}) so that $\hat{b} = DZ^\prime V^{-1}(y - X \hat{\beta}).$ Pre-multiplying by the appropriate matrices it is straightforward to show that these estimates $\hat{\beta}$ and $\hat{b}$ satisfy the equations in (\ref{Henderson:Equations}).

\subsubsection{Algorithms for likelihood function optimization}Iterative numerical techniques are used to optimize the log-likelihood function and estimate the covariance parameters $\theta$. The procedure is subject to the constraint that $R$ and $D$ are both positive definite. The most common iterative algorithms for optimizing the likelihood function are the Newton-Raphson method, which is the preferred method, the expectation maximization (EM) algorithm and the Fisher scoring methods.

The EM algorithm, introduced by \citet{EM}, is an iterative technique for maximizing complicated likelihood functions. The algorithm alternates between performing an expectation (E) step
and the maximization (M) step. The `E' step computes the expectation of the log-likelihood evaluated using the current
estimate for the variables. In the `M' step, parameters that maximize the expected log-likelihood, found on the previous `E' step, are computed. These parameter estimates are then used to determine the distribution of the variables in the next `E' step. The algorithm alternatives between these two steps until convergence is reached.

The main drawback of the EM algorithm is its slow rate of
convergence. Consequently the EM algorithm is rarely used entirely in LME estimation,
instead providing an initial set of values that can be passed to
other optimization techniques.

The Newton Raphson (NR) method is the most common, and recommended technique for ML and
REML estimation. The NR algorithm minimizes an objective function defines as $-2$ times the log likelihood for the covariance parameters $\theta$. At every iteration the NR algorithm requires the
calculation of a vector of partial derivatives, known as the gradient, and the second derivative matrix with respect to the covariance parameters. This is known as the observed Hessian matrix. Due to the Hessian matrix, the NR algorithm is more time-consuming, but convergence is reached with fewer iterations compared to the EM algorithm. The Fisher scoring algorithm is an variant of the NR algorithm that is more numerically stable and likely to converge, but not recommended to obtain final estimates.

\subsubsection{The extended likelihood}

The desire to have an entirely likelihood-based justification for estimates of random effects, in contrast to Henderson's equation, has motivated \citet[page 429]{Pawi:in:2001} to define the \emph{extended likelihood}. He remarks ``In mixed effects modelling the extended likelihood has been called \emph{h-likelihood} (for hierarchical  likelihood) by \cite{Lee:Neld:hier:1996}, while in smoothing literature it is known as the \emph{penalized likelihood} (e.g.\ \citeauthor{Gree:Silv:nonp:1994} \citeyear{Gree:Silv:nonp:1994})." The extended likelihood can be written $L(\beta,\theta,b|y) = p(y|b;\beta,\theta) p(b;\theta)$ and adopting the same distributional assumptions used by \cite{Henderson:1950} yields the log-likelihood function

\begin{eqnarray*}
\ell_h(\beta,\theta,b|y)
& = \displaystyle -\frac{1}{2} \left\{ \log|\Sigma| + (y - X \beta -Zb)'\Sigma^{-1}( y - X \beta -Zb) \right.\\
&  \hspace{0.5in} \left. + \log|D| + b^\prime D^{-1}b \right\}.
\end{eqnarray*}
Given $\theta$, differentiating with respect to $\beta$ and $b$ returns Henderson's equations in (\ref{Henderson:Equations}).
%----------------------------------------------------------------------------------------%
\section{Repeated measurements in LME models}

In many statistical analyzes, the need to determine parameter estimates where multiple measurements are available on each of a set of variables often arises. Further to \citet{lam}, \citet{hamlett} performs an analysis of the correlation of replicate measurements, for two variables of interest, using LME models.

Let $y_{Aij}$ and $y_{Bij}$ be the $j$th repeated observations of the variables of interest $A$ and $B$ taken on the $i$th subject. The number of repeated measurements for each variable may differ for each individual.
Both variables are measured on each time points. Let $n_{i}$ be the number of observations for each variable, hence $2\times n_{i}$ observations in total.

It is assumed that the pair $y_{Aij}$ and $y_{Bij}$ follow a bivariate normal distribution.
\begin{eqnarray*}
\left(
  \begin{array}{c}
    y_{Aij} \\
    y_{Bij} \\
  \end{array}
\right) \sim \mathcal{N}(
    \boldsymbol{\mu}, \boldsymbol{\Sigma})\mbox{   where } \boldsymbol{\mu} = \left(
  \begin{array}{c}
    \mu_{A} \\
    \mu_{B} \\
  \end{array}
\right)
\end{eqnarray*}

The matrix $\Sigma$ represents the variance component matrix between response variables at a given time point $j$.

\[
\boldsymbol{\Sigma} = \left( \begin{array}{cc}
                        \sigma^2_{A} & \sigma_{AB} \\
                        \sigma_{AB} & \sigma^2_{B}\\
                      \end{array}   \right)
\]

$\sigma^2_{A}$ is the variance of variable $A$, $\sigma^2_{B}$ is the variance of variable $B$ and $\sigma_{AB}$ is the covariance of the two variable. It is assumed that $\boldsymbol{\Sigma}$ does not depend on a particular time point, and is the same over all time points.

%------------------------------------------------------------------------------%
\subsection{Formulation of the response vector}
 Information of individual $i$ is recorded in a response vector $\boldsymbol{y}_{i}$. The response vector is constructed by stacking the response of the $2$ responses at the first instance, then the $2$ responses at the second instance, and so on. Therefore the response vector is a $2n_{i} \times 1$ column vector.
The covariance matrix of $\boldsymbol{y_{i}}$ is a $2n_{i} \times 2n_{i}$ positive definite matrix $\boldsymbol{\Omega}_{i}$.

Consider the case where three measurements are taken by both methods $A$ and $B$, $\boldsymbol{y}_{i}$ is a $6 \times 1$ random vector describing the $i$th subject.
\[
\boldsymbol{y}_{i} = (y_{i}^{A1},y_{i}^{B1},y_{i}^{A2},y_{i}^{B2},y_{i}^{A3},y_{i}^{B3}) \prime
\]

The response vector $\boldsymbol{y_{i}}$ can be formulated as an LME model according to Laird-Ware form.
\begin{eqnarray*}
\boldsymbol{y_{i}} = \boldsymbol{X_{i}\beta}  + \boldsymbol{Z_{i}b_{i}} + \boldsymbol{\epsilon_{i}}\\
\boldsymbol{b_{i}} \sim \mathcal{N}(\boldsymbol{0,D})\\
\boldsymbol{\epsilon_{i}} \sim \mathcal{N}(\boldsymbol{0,R_{i}})
\end{eqnarray*}

Information on the fixed effects are contained in a three dimensional vector $\boldsymbol{\beta} = (\beta_{0},\beta_{1},\beta_{2})\prime$. For computational purposes $\beta_{2}$ is conventionally set to zero. Consequently $\boldsymbol{\beta}$ is the solutions of the means of the two methods, i.e. $E(\boldsymbol{y}_{i})  = \boldsymbol{X}_{i}\boldsymbol{\beta}$. The variance covariance matrix $\boldsymbol{D}$ is a general $2 \times 2$ matrix, while $\boldsymbol{R}_{i}$ is a $2n_{i} \times 2n_{i}$ matrix.

%------------------------------------------------------------------------------%
\subsection{Decomposition of the response covariance matrix}

The variance covariance structure can be re-expressed in the following form,
\[
\mbox{Cov}(\mbox{y}_{i}) = \boldsymbol{\Omega_{i}} = \boldsymbol{Z}_{i}\boldsymbol{D}\boldsymbol{Z}_{i}^\prime + \boldsymbol{R_{i}}.
\]

$\boldsymbol{R_{i}}$ can be shown to be the Kronecker product of a correlation matrix $\boldsymbol{V}$ and $\boldsymbol{\Lambda}$. The correlation matrix $\boldsymbol{V}$ of the repeated measures on a given response variable is assumed to be the same for all response variables. Both \citet{hamlett} and \citet{lam} use the identity matrix, with dimensions $n_{i} \times n_{i}$ as the formulation for $\boldsymbol{V}$. \citet{roy} remarks that, with repeated measures, the response for each subject is correlated for each variable, and that such correlation must be taken into account in order to produce a valid inference on correlation estimates.  \citet{roy2006} proposes various correlation structures may be assumed for repeated measure correlations, such as the compound symmetry and autoregressive structures, as alternative to the identity matrix.

However, for the purposes of method comparison studies, the necessary estimates are currently only determinable when the identity matrix is specified, and the results in \citet{roy} indicate its use.

For the response vector described, \citet{hamlett} presents a detailed covariance matrix. A brief summary shall be presented here only. The overall variance matrix is a $6 \times 6$ matrix composed of two types of $2 \times 2$ blocks. Each block represents one separate time of measurement.

\[
\boldsymbol{\Omega}_{i} = \left(
\begin{array}{ccc}
  \boldsymbol{\Sigma} & \boldsymbol{D} & \boldsymbol{D}\\
  \boldsymbol{D} & \boldsymbol{\Sigma} & \boldsymbol{D}\\
  \boldsymbol{D} & \boldsymbol{D} & \boldsymbol{\Sigma}\\
\end{array}\right)
\]

The diagonal blocks are $\Sigma$, as described previously. The $2 \times 2$ block diagonal matrix in $\boldsymbol{\Omega}$ gives $\boldsymbol{\Sigma}$. $\boldsymbol{\Sigma}$ is the sum of the between-subject variability $\boldsymbol{D}$ and the within subject variability $\boldsymbol{\Lambda}$.

$\boldsymbol{\Omega_{i}}$ can be expressed as
\[
\boldsymbol{\Omega_{i}} = \boldsymbol{Z}_{i}\boldsymbol{D}\boldsymbol{Z}_{i}^\prime + ({\boldsymbol{I_{n_{i}}} \otimes \boldsymbol{\Lambda}}).
\]
The notation $\mbox{dim}_{n_{i}}$ means an $n_{i} \times n_{i}$ diagonal block.

\subsection{Correlation terms}
\citet{hamlett} demonstrated how the between-subject and within subject variabilities can be expressed in terms of
correlation terms.

\[
\boldsymbol{D} = \left( \begin{array}{cc}
                        \sigma^2_{A}\rho_{A} & \sigma_{A}\sigma_{b}\rho_{AB}\delta \\
                        \sigma_{A}\sigma_{b}\rho_{AB}\delta & \sigma^2_{B}\rho_{B}\\

                      \end{array}\right)
\]

\[
\boldsymbol{\Lambda} = \left(
\begin{array}{cc}
  \sigma^2_{A}(1-\rho_{A}) & \sigma_{AB}(1-\delta)  \\
    \sigma_{AB}(1-\delta) & \sigma^2_{B}(1-\rho_{B}) \\
\end{array}\right).
\]

$\rho_{A}$ describe the correlations of measurements made by the method $A$ at different times. Similarly $\rho_{B}$ describe the correlation of measurements made by the method $B$ at different times. Correlations among repeated measures within the same method are known as intra-class correlation coefficients. $\rho_{AB}$ describes the correlation of measurements taken at the same same time by both methods. The coefficient $\delta$ is added for when the measurements are taken at different times, and is a constant of less than $1$ for linked replicates. This is based on the assumption that linked replicates measurements taken at the same time would have greater correlation than those taken at different times. For unlinked replicates $\delta$ is simply $1$. \citet{hamlett} provides a useful graphical depiction of the role of each correlation coefficients.



%------------------------------------------------------------------------------------%
\newpage
\section{Limits of agreement in LME models}

Limits of agreement are used extensively for assessing agreement, because they are intuitive and easy to use.
Necessarily their prevalence in literature has meant that they are now the best known measurement for agreement, and therefore any newer methodology would benefit by making reference to them.

\citet{BXC2008} uses LME models to determine the limits of agreement. Between-subject variation for method $m$ is given by $d^2_{m}$ and within-subject variation is given by $\lambda^2_{m}$.  \citet{BXC2008} remarks that for two methods $A$ and $B$, separate values of $d^2_{A}$ and $d^2_{B}$ cannot be estimated, only their average. Hence the assumption that $d_{x}= d_{y}= d$ is necessary. The between-subject variability $\boldsymbol{D}$ and within-subject variability $\boldsymbol{\Lambda}$ can be presented in matrix form,\[
\boldsymbol{D} = \left(%
\begin{array}{cc}
   d^2_{A}& 0 \\
  0 & d^2_{B} \\
\end{array}%
\right)=\left(%
\begin{array}{cc}
   d^2& 0 \\
  0 & d^2\\
\end{array}%
\right),
\hspace{1.5cm}
\boldsymbol{\Lambda} = \left(%
\begin{array}{cc}
   \lambda^2_{A}& 0 \\
  0 & \lambda^2_{B} \\
\end{array}%
\right).
\]

The variance for method $m$ is $d^2_{m}+\lambda^2_{m}$. Limits of agreement are determined using the standard deviation of the case-wise differences between the sets of measurements by two methods $A$ and $B$, given by
\begin{equation}
\mbox{var} (y_{A}-y_{B}) = 2d^2 + \lambda^2_{A}+ \lambda^2_{B}.
\end{equation}
Importantly the covariance terms in both variability matrices are zero, and no covariance component is present.

\citet{BXC2008} presents a data set `fat', which is a comparison of measurements of subcutaneous fat
by two observers at the Steno Diabetes Center, Copenhagen. Measurements are in millimeters
(mm). Each person is measured three times by each observer. The observations are considered to be `true' replicates.

A linear mixed effects model is formulated, and implementation through several software packages is demonstrated.
All of the necessary terms are presented in the computer output. The limits of agreement are therefore,
\begin{equation}
0.0449  \pm 1.96 \times  \sqrt{2 \times 0.0596^2 + 0.0772^2 + 0.0724^2} = (-0.220,  0.309).
\end{equation}

\citet{roy} has demonstrated a methodology whereby $d^2_{A}$ and $d^2_{B}$ can be estimated separately. Also covariance terms are present in both $\boldsymbol{D}$ and $\boldsymbol{\Lambda}$. Using Roy's methodology, the variance of the differences is
\begin{equation}
\mbox{var} (y_{iA}-y_{iB})= d^2_{A} + \lambda^2_{B} + d^2_{A} + \lambda^2_{B} - 2(d_{AB} + \lambda_{AB})
\end{equation}
All of these terms are given or determinable in computer output.
The limits of agreement can therefore be evaluated using
\begin{equation}
\bar{y_{A}}-\bar{y_{B}} \pm 1.96 \times \sqrt{ \sigma^2_{A} + \sigma^2_{B}  - 2(\sigma_{AB})}.
\end{equation}

For Carstensen's `fat' data, the limits of agreement computed using Roy's
method are consistent with the estimates given by \citet{BXC2008}; $0.044884  \pm 1.96 \times  0.1373979 = (-0.224,  0.314).$

\subsection{Linked replicates}

\citet{BXC2008} proposes the addition of an random effects term to their model when the replicates are linked. This term is used to describe the `item by replicate' interaction, which is independent of the methods. This interaction is a source of variability independent of the methods. Therefore failure to account for it will result in variability being wrongly attributed to the methods.

\citet{BXC2008} introduces a second data set; the oximetry study. This study done at the Royal ChildrenÂ’s Hospital in
Melbourne to assess the agreement between co-oximetry and pulse oximetry in small babies.

In most cases, measurements were taken by both method at three different times. In some cases there are either one or two pairs of measurements, hence the data is unbalanced. \citet{BXC2008} describes many of the children as being very sick, and with very low oxygen saturations levels. Therefore it must be assumed that a biological change can occur in interim periods, and measurements are not true replicates.

\citet{BXC2008} demonstrate the necessity of accounting for linked replicated by comparing the limits of agreement from the `oximetry' data set using a model with the additional term, and one without. When the interaction is accounted for the limits of agreement are (-9.62,14.56). When the interaction is not accounted for, the limits of agreement are (-11.88,16.83). It is shown that the failure to include this additional term results in an over-estimation of the standard deviations of differences.

Limits of agreement are determined using Roy's methodology, without adding any additional terms, are found to be consistent with the `interaction' model; $(-9.562, 14.504 )$. Roy's methodology assumes that replicates are linked. However, following Carstensen's example, an addition interaction term is added to the implementation of Roy's model to assess the effect, the limits of agreement estimates do not change. However there is a conspicuous difference in within-subject matrices of Roy's model and the modified model (denoted $1$ and $2$ respectively);
\begin{equation}
\hat{\boldsymbol{\Lambda}}_{1}= \left(\begin{array}{cc}
 16.61 &	11.67\\
11.67 & 27.65 \end{array}\right) \qquad
\boldsymbol{\hat{\Lambda}}_{2}= \left( \begin{array}{cc}
    7.55 & 2.60 \\
    2.60 & 18.59 \end{array} \right).
\end{equation}

\noindent (The variance of the additional random effect in model $2$ is $3.01$.)

\citet{akaike} introduces the Akaike information criterion ($AIC$), a model
selection tool based on the likelihood function. Given a data set, candidate models
are ranked according to their AIC values, with the model having the lowest AIC being considered the best fit.Two candidate models can said to be equally good if there is a difference of less than $2$ in their AIC values.

The Akaike information criterion (AIC) for both models are $AIC_{1} = 2304.226$ and $AIC_{2} = 2306.226$ , indicating little difference in models. The AIC values for the Carstensen `unlinked' and `linked' models are $1994.66$ and $1955.48$ respectively, indicating an improvement by adding the interaction term.

The $\boldsymbol{\hat{\Lambda}}$ matrices are informative as to the difference between Carstensen's unlinked and linked models. For the oximetry data, the covariance terms (given above as 11.67 and 2.6 respectively ) are of similar magnitudes to the variance terms. Conversely for the `fat' data the covariance term ($-0.00032$) is negligible. When the interaction term is added to the model, the covariance term remains negligible. (For the `fat' data, the difference in AIC values is also approximately $2$).

To conclude, Carstensen's models provided a rigorous way to determine limits of agreement, but don't provide for the computation of $\boldsymbol{\hat{D}}$ and $\boldsymbol{\hat{\Lambda}}$. Therefore the test's proposed by \citet{roy} can not be implemented. Conversely, accurate limits of agreement as determined by Carstensen's model may also be found using Roy's method. Addition of the interaction term erodes the capability of Roy's methodology to compare candidate models, and therefore shall not be adopted.

Finally, to complement the blood pressure (i.e.`J vs S') method comparison from the previous section (i.e.`J vs S'), the limits of agreement are $15.62 \pm 1.96 \times 20.33 = (-24.22, 55.46)$.)
\newpage
\section{Extension of Roy's methodology}
Roy's methodology is constructed to compare two methods in the presence of replicate measurements. Necessarily it is worth examining whether this methodology can be adapted for different circumstances.

An implementation of Roy's methodology, whereby three or more methods are used, is not feasible due to computational restrictions. Specifically there is a failure to reach convergence before the iteration limit is reached. This may be due to the presence of additional variables, causing the problem of non-identifiability. In the case of two variables, it is required to estimate two variance terms and four correlation terms, six in all. For the case of three variabilities, three variance terms must be estimated as well as nine correlation terms, twelve in all. In general for $n$ methods has $2 \times T_{n}$ variance terms, where $T_n$ is the triangular number for $n$, i.e. the addition analogue of the factorial. Hence the computational complexity quite increases substantially for every increase in $n$.

Should an implementation be feasible, further difficulty arises when interpreting the results. The fundamental question is whether two methods have close agreement so as to be interchangeable. When three methods are present in the model, the null hypothesis is that all three methods have the same variability relevant to the respective tests. The outcome of the analysis will either be that all three are interchangeable or that all three are not interchangeable.

The tests would not be informative as to whether any two of those three were interchangeable, or equivalently if one method in particular disagreed with the other two. Indeed it is easier to perform three pair-wise comparisons separately and then to combine the results.

Roy's methodology is not suitable for the case of single measurements because it follows from the decomposition for the covariance matrix of the response vector $y_{i}$, as presented in \citet{hamlett}. The decomposition depends on the estimation of correlation terms, which would be absent in the single measurement case. Indeed there can be no within-subject variability if there are no repeated terms for it to describe. There would only be the covariance matrix of the measurements by both methods, which doesn't require the use of LME models. To conclude, simpler existing methodologies, such as Deming regression, would be the correct approach where there only one measurements by each method.

\section{Conclusion}
\citet{BXC2008} and \citet{roy} highlight the need for method comparison methodologies suitable for use in the presence of replicate measurements. \citet{roy} presents a comprehensive methodology for assessing the agreement of two methods, for replicate measurements. This methodology has the added benefit of overcoming the problems of unbalanced data and unequal numbers of replicates. Implementation of the methodology, and interpretation of the results, is relatively easy for practitioners who have only basic statistical training. Furthermore, it can be shown that widely used existing methodologies, such as the limits of agreement, can be incorporated into Roy's methodology.





%----------------------------------------------------------------------------------------%
\newpage

\section{Linear Mixed effects Models}
A linear mixed effects (LME) model is a statistical model containing both fixed effects and random effects, also known as variance components. LME models are a generalization of the classical linear model, which contain fixed effects only. When the levels of factors are considered to be sampled from a population,
and each such level is not of particular interest, they are considered random quantities with associated variances.
The effects of the levels, as described, are known as random effects. Random effects are represented by unobservable
normally distributed random variables. Conversely fixed effects are considered non-random and the
levels of each factor are of specific interest.
%LME models are useful models when considering repeated measurements or grouped observations. 

\citet{Fisher4} introduces variance components models for use in genetical studies. Whereas an estimate for variance must take an non-negative value, an individual variance component, i.e. a component of the overall variance, may be negative.

The methodology has developed since, including contributions from
\citet{tippett}, who extend the use of variance components into linear models, and \citet{eisenhart}, who introduced the `mixed model' terminology and formally distinguished between mixed and random effects models. \citet{Henderson:1950} devised a methodology for deriving estimates for both the fixed effects and the random effects, using a set of equations that would become known as `mixed model equations' or `Henderson's equations'. 
LME methodology is further enhanced by Henderson's later works \citep{Henderson53, Henderson59,Henderson63,Henderson73,Henderson84a}. The key features of Henderson's work shall be discussed in depth in due course.

\citet{HartleyRao} demonstrated that unique estimates of the variance components could be obtained using maximum likelihood methods. These estimates would later become known as the maximum likelihood (ML) estimates. However these estimates are known to be biased downwards, because of the assumption that the fixed estimates are known, rather than being estimated from the data. \citet{PattersonThompson} produced an alternative set of estimates, known as the restricted maximum likelihood (REML) estimates, that do not require the fixed effects to be known. Both ML and REML estimation shall be reverted to in due course.

\citet{LW82} provides a form of notation for notation for LME models that has since become the standard form, or the basis for more complex formulations. Due to computation complexity, linear mixed effects models have not seen widespread use until many well known statistical software applications began facilitating them. SAS Institute added PROC MIXED to its software suite in 1992 \citep{singer}. \citet{PB} described how to compute LME models in the \texttt{R} environment.

Using Laird-Ware form, the LME model is commonly described in matrix form,
\begin{equation}
y = X\beta + Zb + \epsilon
\end{equation}

\noindent where $y$ is a vector of $N$ observable random variables, $\beta$ is a vector of $p$ fixed effects, $X$ and $Z$ are $N \times p$ and $N \times q$ known matrices, and $b$ and $\epsilon$  are vectors of $q$ and $N,$ respectively, random effects such that $\mathrm{E}(b)=0, \ \mathrm{E}(\epsilon)=0$
and
\[
\mathrm{var}
\pmatrix{
  b \cr
  \epsilon }  =
\pmatrix{
  D & 0 \cr
  0 & \Sigma }
\]
where $D$ and $\Sigma$ are positive definite matrices parameterized by an unknown variance component parameter vector $ \theta.$ The notation provided here is generic, and will be adapted to accord with complex formulations that will be encountered in due course.

\subsection{Likelihood and estimation}

Likelihood is the hypothetical probability that an event that has
already occurred would yield a specific outcome. Likelihood
differs from probability in that probability refers to future
occurrences, while likelihood refers to past known outcomes.

The likelihood function ($L(\theta)$)is a fundamental concept in statistical
inference. It indicates how likely a particular population is to
produce an observed sample. The set of values that maximize the
likelihood function are considered to be optimal, and are used as
the estimates of the parameters. For computational ease, it is common to use the logarithm of the likelihood function, known simply as the log-likelihood ($\ell(\theta)$).

\subsubsection{Likelihood-based tools}
Likelihood functions provide the basis for two important statistical concepts that shall be further referred to; the likelihood ratio test and the Akaike information criterion.

Likelihood ratio tests are a class of tests based on the comparison of the values of the likelihood functions of two
candidate models. LRTs can be used to test hypotheses about covariance parameters or fixed effects parameters in the context of LMEs. The test statistic for the likelihood ratio test is the difference of the log-likelihood functions, multiplied by $-2$. The probability distribution of the test statistic is approximated by the $\chi^2$ distribution with ($\nu_{1} - \nu_{2}$) degrees of freedom, where $\nu_{1}$  and $\nu_{2}$ are the degrees of freedom of models 1 and 2 respectively.

\citet{akaike} introduces the Akaike information criterion ($AIC$), a model selection tool based on the likelihood function. Given a data set, candidate models are ranked according to their AIC values, with the model having the lowest AIC being considered the best fit.

\subsubsection{Likelihood estimation techniques}
Maximum likelihood and restricted maximum likelihood have become the most common strategies for estimating the variance component parameter $\theta.$ Maximum likelihood estimation obtains
parameter estimates by optimizing the likelihood function. To obtain ML estimate the likelihood is constructed as a function of the parameters in the specified LME model. The maximum likelihood estimates (MLEs) of the parameters are the values of the arguments that maximize the likelihood function. The REML approach is a variant of maximum likelihood estimation which does not base estimates on a maximum likelihood fit of all the information, but instead uses a likelihood function derived from a data set, transformed to remove the irrelevant influences \citep{REMLDefine}.

Restricted maximum likelihood is often preferred to maximum likelihood because REML estimation reduces the bias in the variance component by taking into account the loss of degrees of freedom that results
from estimating the fixed effects in $\boldsymbol{\beta}$. Restricted maximum likelihood also handles high correlations more effectively, and is less sensitive to outliers than maximum likelihood.  The problem with REML for model building is that the likelihoods obtained for different fixed effects are not comparable. Hence it is not valid to compare models with different fixed effects using a likelihood ratio test or AIC when REML is used to
estimate the model. Therefore models derived using ML must be used instead.

\subsection{Henderson's equations}

\cite{Henderson:1950} made the (ad-hoc) distributional assumptions $y|b \sim \mathrm{N} (X \beta + Zb, \Sigma)$ and $b \sim \mathrm{N}(0,D),$ and proceeded to maximize the joint density of $y$ and $b$
\begin{equation}
\left|
\pmatrix{
  D & 0 \cr
  0 & \Sigma }
  \right|^{-\frac{1}{2}}
\exp
\left\{ -\frac{1}{2}
\pmatrix{
  b \cr
  y - X \beta -Zb
  }^\prime
\pmatrix{
  D & 0 \cr
  0 & \Sigma }^{-1}
\pmatrix{
  b \cr
  y - X \beta -Zb
  }
\right\},
\label{u&beta:JointDensity}
\end{equation}
with respect to $\beta$ and $b,$ which ultimately requires minimizing the criterion
\begin{equation}
(y - X \beta -Zb)'\Sigma^{-1}(y - X \beta -Zb) + b^\prime D^{-1}b.
\label{Henderson:Criterion}
\end{equation}
This leads to the mixed model equations
\begin{equation}
\pmatrix{
  X^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}Z
  \cr
  Z^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}X + D^{-1}
  }
\pmatrix{
    \beta \cr
  b
  }
  =
\pmatrix{
  X^\prime\Sigma^{-1}y \cr
  Z^\prime\Sigma^{-1}y
  }.
\label{Henderson:Equations}
\end{equation}
\cite{Robi:BLUP:1991} points out that although \cite{Henderson:1950} initially referred to the estimates $\hat{\beta}$ and $\hat{b}$ from (\ref{Henderson:Equations}) as ``joint maximum likelihood estimates". \cite{Henderson:1973} later advised that these estimates should not be referred to as ``maximum likelihood" as the function being maximized in (\ref{Henderson:Criterion}) is a joint density rather than a likelihood function.

\subsubsection{Estimation of the fixed parameters}

The vector $y$ has marginal density $y \sim \mathrm{N}(X \beta,V),$ where $V = \Sigma + ZDZ^\prime$ is specified through the variance component parameters $\theta.$ The log-likelihood of the fixed parameters $(\beta, \theta)$ is
\begin{equation}
\ell (\beta, \theta|y) =
-\frac{1}{2} \log |V| -\frac{1}{2}(y -
X \beta)'V^{-1}(y -
X \beta), \label{Likelihood:MarginalModel}
\end{equation}
and for fixed $\theta$ the estimate $\hat{\beta}$ of $\beta$ is obtained as the solution of
\begin{equation}
(X^\prime V^{-1}X) {\beta} = X^\prime V^{-1}y.
\label{mle:beta:hat}
\end{equation}

Substituting $\hat{\beta}$ from (\ref{mle:beta:hat}) into $\ell(\beta, \theta|y)$ from (\ref{Likelihood:MarginalModel}) returns the \emph{profile} log-likelihood
\begin{eqnarray*}
\ell_P(\theta \mid y) &=& \ell(\hat{\beta}, \theta \mid y) \\
&=& -\frac{1}{2} \log |V| -\frac{1}{2}(y - X \hat{\beta})'V^{-1}(y - X \hat{\beta})
\end{eqnarray*}
of the variance parameter $\theta.$ Estimates of the parameters $\theta$ specifying $V$ can be found by maximizing $\ell_P(\theta \mid y)$ over $\theta.$ These are the ML estimates. For REML estimation the \emph{restricted} log-likelihood is defined as
\[
\ell_R(\theta \mid y) =
\ell_P(\theta \mid y) -\frac{1}{2} \log |X^\prime VX |.
\]



\subsubsection{Estimation of the random effects}

The established approach for estimating the random effects is to use the best linear predictor of $b$ from $y,$ which for a given $\beta$ equals $DZ^\prime V^{-1}(y - X \beta).$ In practice $\beta$ is replaced by an estimator such as $\hat{\beta}$ from (\ref{mle:beta:hat}) so that $\hat{b} = DZ^\prime V^{-1}(y - X \hat{\beta}).$ Pre-multiplying by the appropriate matrices it is straightforward to show that these estimates $\hat{\beta}$ and $\hat{b}$ satisfy the equations in (\ref{Henderson:Equations}).

\subsection{Algorithms for likelihood function optimization}Iterative numerical techniques are used to optimize the log-likelihood function and estimate the covariance parameters $\theta$. The procedure is subject to the constraint that $R$ and $D$ are both positive definite. The most common iterative algorithms for optimizing the likelihood function are the Newton-Raphson method, which is the preferred method, the expectation maximization (EM) algorithm and the Fisher scoring methods.

The EM algorithm, introduced by \citet{EM}, is an iterative technique for maximizing complicated likelihood functions. The algorithm alternates between performing an expectation (E) step
and the maximization (M) step. The `E' step computes the expectation of the log-likelihood evaluated using the current
estimate for the variables. In the `M' step, parameters that maximize the expected log-likelihood, found on the previous `E' step, are computed. These parameter estimates are then used to determine the distribution of the variables in the next `E' step. The algorithm alternatives between these two steps until convergence is reached.

The main drawback of the EM algorithm is its slow rate of
convergence. Consequently the EM algorithm is rarely used entirely in LME estimation,
instead providing an initial set of values that can be passed to
other optimization techniques.

The Newton Raphson (NR) method is the most common, and recommended technique for ML and
REML estimation. The NR algorithm minimizes an objective function
defines as $-2$ times the log likelihood for the covariance
parameters $\theta$. At every iteration the NR algorithm requires the
calculation of a vector of partial derivatives, known as the
gradient, and the second derivative matrix with respect to the
covariance parameters. This is known as the observed Hessian
matrix. Due to the Hessian matrix, the NR algorithm is more time-consuming, but convergence is reached with fewer iterations, compared to the EM algorithm. The Fisher scoring algorithm is an
variant of the NR algorithm, that is more numerically stable and likely to converge, but not recommended to obtain final estimates.

\subsection{The extended likelihood}

The desire to have an entirely likelihood-based justification for estimates of random effects has motivated \citet[page 429]{Pawi:in:2001} to define the \emph{extended likelihood}. He remarks ``In mixed effects modelling the extended likelihood has been called \emph{h-likelihood} (for hierarchical  likelihood) by \cite{Lee:Neld:hier:1996}, while in smoothing literature it is known as the \emph{penalized likelihood} (e.g.\ \citeauthor{Gree:Silv:nonp:1994} \citeyear{Gree:Silv:nonp:1994})." The extended likelihood can be written $L(\beta,\theta,b|y) = p(y|b;\beta,\theta) p(b;\theta)$ and adopting the same distributional assumptions used by \cite{Henderson:1950} yields the log-likelihood function
\begin{eqnarray*}
\ell_h(\beta,\theta,b|y)
& = \displaystyle -\frac{1}{2} \left\{ \log|\Sigma| + (y - X \beta -Zb)'\Sigma^{-1}( y - X \beta -Zb) \right.\\
&  \hspace{0.5in} \left. + \log|D| + b^\prime D^{-1}b \right\}.
\end{eqnarray*}
Given $\theta$, differentiating with respect to $\beta$ and $b$ returns Henderson's equations in (\ref{Henderson:Equations}).


Henderson's equations in (\ref{Henderson:Equations}) can be rewritten $( T^\prime W^{-1} T ) \delta = T^\prime W^{-1} y_{a} $ using
\[
\delta = \pmatrix{\beta \cr b},
\ y_{a} = \pmatrix{
  y \cr \psi
  },
\ T = \pmatrix{
  X & Z  \cr
  0 & I
  },
\ \textrm{and} \ W = \pmatrix{
  \Sigma & 0  \cr
  0 &  D },
\]
where \cite{Lee:Neld:Pawi:2006} describe $\psi = 0$ as quasi-data with mean $\mathrm{E}(\psi) = b.$ Their formulation suggests that the joint estimation of the coefficients $\beta$ and $b$ of the linear mixed effects model can be derived via a classical augmented general linear model $y_{a} = T\delta + \varepsilon$ where $\mathrm{E}(\varepsilon) = 0$ and $\mathrm{var}(\varepsilon) = W,$ with \emph{both} $\beta$ and $b$ appearing as fixed parameters.










%------------------------------------------------------------------------------------%
\newpage                                                                    % - Section 4
%----------------------------------------------------------------------------------------%
\section{Repeated measurements in LME models}

\citet{Lam} used ML estimation to estimate the true correlation between the variables when
the measurements are linked over time. The methodology relies on the assumption that the two variables with repeated measures follow a multivariate normal distribution. The methodology currently does not extend to any more than two cases. The MLE of the correlation takes into account the dependency among repeated measures.

The true correlation $\rho_{xy}$ is repeated measurements can be considered as having two components: between subject and within-subject correlation. The usefulness of estimating repeated measure correlation coefficients is the calculation of between-method and within-method variabilities are produced as by-products.


%------------------------------------------------------------------------------%
\subsection{Statistical model}
Let $y_{Aij}$ and $y_{Bij}$ be the $j$th repeated observations of the variables of interest $A$ and $B$ taken on the $i$th subject. The number of repeated measurements for each variable may differ for each individual.
Both variables are measured on each time points. Let $n_{i}$ be the number of observations for each variable, hence $2\times n_{i}$ observations in total.

It is assumed that the pair $y_{Aij}$ and $y_{Bij}$ follow a bivariate normal distribution.
\begin{eqnarray}
\left(
  \begin{array}{c}
    y_{Aij} \\
    y_{Bij} \\
  \end{array}
\right) \sim \mathcal{N}(
    \boldsymbol{\mu}, \boldsymbol{\Sigma})\mbox{   where } \boldsymbol{\mu} = \left(
  \begin{array}{c}
    \mu_{A} \\
    \mu_{B} \\
  \end{array}
\right)
\end{eqnarray}
The matrix $\boldsymbol{\Sigma}$ represents the variance component matrix between response variables at a given time point $j$.
\begin{equation}
\boldsymbol{\Sigma} = \left( \begin{array}{cc}
                        \sigma^2_{A} & \sigma_{AB} \\
                        \sigma_{AB} & \sigma^2_{B}\\
                      \end{array}\right)
\end{equation}
$\sigma^2_{A}$ is the variance of variable $A$, $\sigma^2_{B}$ is the variance of variable $B$ and $\sigma_{AB}$ is the covariance of the two variable. It is assumed that $\boldsymbol{\Sigma}$ does not depend on a particular time point, and is the same over all time points.

%------------------------------------------------------------------------------%
\subsection{Formulation of the response vector}
 Information of individual $i$ is recorded in a response vector $\boldsymbol{y_{i}}$. The response vector is constructed by stacking the response of the $2$ responses at the first time point, then the $2$ responses at the second time point, and so on. Therefore the response vector is a $2n_{i} \times 1$ column vector.
The covariance matrix of $\boldsymbol{y_{i}}$ is a $2n_{i} \times 2n_{i}$ positive definite matrix $\boldsymbol{\Omega}$.

Consider the case where three measurements are taken by both methods $A$ and $B$, $\boldsymbol{y_{i}}$ is a $6 \times 1$ random vector describing the $i$th subject.
\begin{equation}
\boldsymbol{y}_{i} = (y_{i}^{A1},y_{i}^{B1},y_{i}^{A2},y_{i}^{B2},y_{i}^{A3},y_{i}^{B3}) \prime
\end{equation}

The response vector $\boldsymbol{y_{i}}$ can be formulated as an LME model according to Laird-Ware form.
\begin{eqnarray}
\boldsymbol{y_{i}} = \boldsymbol{X_{i}\beta}  + \boldsymbol{Z_{i}b_{i}} + \boldsymbol{\epsilon_{i}}\\
\boldsymbol{b_{i}} \sim \mathcal{N}(\boldsymbol{0,D})\\
\boldsymbol{\epsilon_{i}} \sim \mathcal{N}(\boldsymbol{0,R_{i}})
\end{eqnarray}

$\boldsymbol{\beta}$ is a three dimensional vector containing the fixed effects. $\boldsymbol{\beta} = (\beta_{0},\beta_{1},\beta_{2})\prime$. $\beta_{2}$ is usually set to zero. Consequently $\boldsymbol{\beta}$ is the solutions of the means of the two methods, i.e. $E(\boldsymbol{y_{i}}  = \boldsymbol{X_{i}\beta}$. The variance covariance matrix $\boldsymbol{D}$ is a general $2 \times 2$ matrix, while $\boldsymbol{R_{i}}$ is a $2n_{i} \times 2n_{i}$ matrix.

%------------------------------------------------------------------------------%
\subsection{Decomposition of the response covariance matrix}

The variance covariance structure can be re-expressed in the following form,
\begin{equation}
\mbox{Cov}(\mbox{y}_{i}) = \boldsymbol{\Omega_{i}} = \boldsymbol{Z}_{i}\boldsymbol{D}\boldsymbol{Z}_{i}\prime + \boldsymbol{R_{i}}.
\end{equation}

$\boldsymbol{R_{i}}$ can be shown to be the Kronecker product of a correlation matrix $\boldsymbol{V}$ and $\boldsymbol{\Lambda}$. The correlation matrix $\boldsymbol{V}$ of the repeated measures on a given response variable is assumed to be the same for all response variables. \citet{roy} remarks that, with repeated measures, the response for each subject is correlated for each variable, and that such correlation must be taken into account in order to produce a valid inference. Various error structures may be assumed for repeated measure correlations. However both \citet{hamlett} and \citet{Lam} use the identity matrix, with dimensions $n_{i} \times n_{i}$ as the formulation for $\boldsymbol{V}$. This has the benefit of being simple to implement. Roy's results also indicate the use of the identity matrix.

For the response vector described, \citet{hamlett} presents a detailed covariance matrix. A brief summary shall be presented here only. The overall variance matrix is a $6 \times 6$ matrix composed of two types of $2 \times 2$ blocks. Each block represents one separate time of measurement.

\begin{equation}
\boldsymbol{\Omega}_{i} = \left(
\begin{array}{ccc}
  \boldsymbol{\Sigma} & \boldsymbol{D} & \boldsymbol{D}\\
  \boldsymbol{D} & \boldsymbol{\Sigma} & \boldsymbol{D}\\
  \boldsymbol{D} & \boldsymbol{D} & \boldsymbol{\Sigma}\\
\end{array}\right)
\end{equation}

The diagonal blocks are $\Sigma$, as described previously. The $2 \times 2$ block diagonal matrix in $\boldsymbol{\Omega}$ gives $\boldsymbol{\Sigma}$. $\boldsymbol{\Sigma}$ is the sum of the between-subject variability $\boldsymbol{D}$ and the within subject variability $\boldsymbol{\Lambda}$.

$\boldsymbol{\Omega_{i}}$ can be expressed as
\begin{equation}
\boldsymbol{\Omega_{i}} = \boldsymbol{Z}_{i}\boldsymbol{D}\boldsymbol{Z}_{i}\prime + ({\boldsymbol{I_{n_{i}}} \otimes \boldsymbol{\Lambda}}).
\end{equation}
The notation $\mbox{dim}_{n_{i}}$ means an $n_{i} \times n_{i}$ diagonal block.

\subsection{Correlation terms}
\citet{hamlett} demonstrated how the between-subject and within subject variabilities can be expressed in terms of
correlation terms.

\begin{equation}
\boldsymbol{D} = \left( \begin{array}{cc}
                        \sigma^2_{A}\rho_{A} & \sigma_{A}\sigma_{b}\rho_{AB}\delta \\
                        \sigma_{A}\sigma_{b}\rho_{AB}\delta & \sigma^2_{B}\rho_{B}\\
                      \end{array}\right)
\end{equation}

\begin{equation}
\boldsymbol{\Lambda} = \left(
\begin{array}{cc}
  \sigma^2_{A}(1-\rho_{A}) & \sigma_{AB}(1-\delta)  \\
    \sigma_{AB}(1-\delta) & \sigma^2_{B}(1-\rho_{B}) \\
\end{array}\right).
\end{equation}

$\rho_{A}$ describe the correlations of measurements made by the method $A$ at different times. Similarly $\rho_{B}$ describe the correlation of measurements made by the method $B$ at different times. Correlations among repeated measures within the same method are known as intra-class correlation coefficients. $\rho_{AB}$ describes the correlation of measurements taken at the same same time by both methods. The coefficient $\delta$ is added for when the measurements are taken at different times, and is a constant of less than $1$ for linked replicates. This is based on the assumption that linked replicates measurements taken at the same time would have greater correlation than those taken at different times. For unlinked replicates $\delta$ is simply $1$. \citet{hamlett} provides a useful graphical depiction of the role of each correlation coefficients.

%----------------------------------------------------------------------------------------%

\newpage
\section{Using LMEs for method comparison}
\citet{BXC2008} remarks upon `by-hand' approaches advocated in \citet{BA99} discouragingly, describing them as tedious, unnecessary and `outdated'. Due to the prevalence of modern statistical software, \citet{BXC2008} advocates the adoption of computer based approaches to method comparison studies, allowing the use of LME models that would not have been feasible otherwise. Rather than using the `by hand' methods, estimates for required parameters can be gotten directly from output code. Furthermore, using computer approaches removes constraints, such as the need for the design to be perfectly balanced.
\newpage
\section{Roy's variability tests}

For the purposes of method comparison, Roy presents a methodology utilising linear mixed effects model. The formulation contains a Kronecker product covariance structure in a doubly multivariate setup. This methodology provides for the formal testing of inter-method bias, between-subject variability and within-subject variability of two methods. By doubly multivariate set up, Roy means that the information on each patient or item is multivariate at two levels, the number of methods and number of replicated measurements. Further to \citet{Lam}, it is assumed that the replicates are linked over time. However it is easy to modify to the unlinked case.

Roy sets out three conditions for two methods to be considered in agreement. Firstly that there be no significant bias. Second that there is no difference in the between-subject variabilities, and lastly that there is no significant difference in the within-subject variabilities. Should both the second and third conditions be fulfilled, then the overall variabilities of both methods would be equal. Roy additionally uses the overall correlation coefficient to provide extra information about the comparison, with a minimum of 0.82 being required.

Roy proposes a series of three tests on the variance components of an LME model. For these tests, four candidate models are constructed. The difference in the models are specifically in how the the $D$ and $\Lambda$ matrices are constructed, using either an unstructured form or a compound symmetry form. The first model is compared against each of three other models successively.

\subsection{Testing Procedures}
Roy's methodology requires the construction of four candidate models. The first candidate model is compared to each of the three other models successively. It is the alternative model in each of the three tests, with the other three models acting as the respective null models.

The likelihood ratio test is the procedure used to compare the fit of two models. For each candidate model, the `-2 log likelihood' ($M2LL$) is computed. The test statistic for each of the three hypothesis tests is the difference of the $M2LL$ for each pair of models. If the $p-$value in each of the respective tests exceed as significance level chosen by the analyst, then the null model must be rejected.

\begin{equation}
-2\mbox{ ln }\Lambda_{d} =  [ M2LL \mbox{ under }H_{0} \mbox{ model}] - [ M2LL \mbox{ under }H_{A} \mbox{ model}]
\end{equation}

These test statistics follow a chi-square distribution with the degrees of freedom computed as the difference of the LRT degrees of freedom.

\begin{equation}
\nu = [\mbox{ LRT df under }H_{0} \mbox{ model}] - [\mbox{ LRT df under }H_{A} \mbox{ model}]
\end{equation}

The probability distribution of the test statistic can be approximated by a chi-square distribution with ($\nu_1$ - $\nu_2$) degrees of freedom, where $\nu_1$ and $\nu_2$ are the degrees of freedom of models 1 and 2 respectively.

Likelihood ratio tests are very simple to implement in \texttt{R}, simply use the 'anova()' commands. Sample output will be given for each variability test.

\subsection{Test for inter-method bias}
Bias is determinable by examination of the 't-table'. Estimate for both methods are given, and the bias is simply the difference between the two. Because the $R$ implementation does not account for an intercept term, a $p-$value is not given. Should a $p-$value be required specifically for the bias, and simple restructuring of the model is required wherein an intercept term is included. Output from a second implementation will yield a $p-$value.

\subsection{Correlation coefficient}
In addition to the variability tests, Roy advises that it is preferable that a correlation of greater than $0.82$ exist for two methods to be considered interchangeable. However if two methods fulfil all the other conditions for agreement, failure to comply with this one can be overlooked. Indeed Roy demonstrates that placing undue importance to it can lead to incorrect conclusions.
\citet{roy} remarks that PROC MIXED only gives overall correlation coefficients, but not their variances. Similarly variance are not determinable in \texttt{R} as yet either. Consequently it is not possible to carry out inferences based on all overall correlation coefficients.
%----------------------------------------------------------------------------------------%
\newpage
\section{Demonstration of Roy's testing}
Roy provides three case studies, using data sets well known in method comparison studies, to demonstrate how the methodology should be used. The first two examples used are from the `blood pressure' data set introduced by \citet{BA99}. The data set is a tabulation of simultaneous measurements of systolic blood pressure were made by each of two experienced observers (denoted `J' and `R') using a sphygmomanometer and by a semi-automatic blood pressure monitor (denoted `S'). Three sets of readings were made in quick succession. Roy compares the `J' and `S' methods in his first example, and the `R' and `S' methods in his second.
%--------------------------------------------------%
\subsection{Matrix structures}
Before discussing the tests, it is useful to point out the difference between symmetric form and compound symmetry form. Consider a generic matrix $A$,

\begin{equation}
\boldsymbol{A} = \left( \begin{array}{cc}
    a_{11} & a_{12}  \\
    a_{21} & a_{22}  \\
    \end{array}\right).
\end{equation}

A symmetric matrix allows the diagonal terms $a_{11}$ and $a_{22}$ to differ.
The compound symmetry structure requires that both of these terms be equal, i.e $a_{11} = a_{22}$.

%--------------------------------------------------%
\subsection{Variability test 1}
This is a test on whether both methods $A$ and $B$ have the same between-subject variability or not.
\begin{eqnarray}
H_{0}: \mbox{ }d_{A}  = d_{B} \\
H_{A}: \mbox{ }d_{A}  \neq d_{B}
\end{eqnarray}
When implemented using \texttt{R}, this test is facilitated by constructing a model specifying a symmetric form for $D$ (i.e. the alternative model) and comparing it with a model that has compound symmetric form for $D$ (i.e. the null model). For this test $\boldsymbol{\hat{\Lambda}}$ has a symmetric form for both models, and will be the same for both.

%--------------------------------------------------%
\subsubsection{Bland-Altman's blood data}
With the alternative model, the MLE of the between-subject variance covariance matrix is given by
\begin{equation}
\boldsymbol{\hat{D}_{Symm}} = \left( \begin{array}{cc}
    923.98 & 785.24  \\
    785.24 & 971.30  \\
    \end{array}\right)
\end{equation}

With the null model the MLE is as follows:

\begin{equation}
\boldsymbol{\hat{D}_{CS}} = \left( \begin{array}{cc}
    946.50 & 784.32  \\
    784.32 & 946.50  \\
    \end{array}\right)
\end{equation}
A likelihood ratio test is perform to determine which model is more suitable. The outcome of this test is presented in the following \texttt{R} code.
\begin{verbatim}
> anova(MCS1,MCS2)
>
>
     Model df    AIC    BIC  logLik   Test L.Ratio p-value
MCS1     1  8 4077.5 4111.3 -2030.7
MCS2     2  7 4075.6 4105.3 -2030.8 1 vs 2 0.15291  0.6958
\end{verbatim}

The test statistic is the difference of the $-2$ log likelihoods; $0.15291$. The $p-$value is $0.6958$. Therefore we fail to reject the hypothesis that both have the same between-subject variabilities.

%---------------------------------------------%
\subsection{Variability test 2}

This is a test on whether both methods $A$ and $B$ have the same within-subject variability or not.

\begin{eqnarray}
H_{0}: \mbox{ }\lambda_{A}  = \lambda_{B} \\
H_{A}: \mbox{ }\lambda_{A}  = \lambda_{B}
\end{eqnarray}

This model is performed in the same manner as the first test, only reversing the roles of $\boldsymbol{\hat{D}}$ and $\boldsymbol{\hat{\Lambda}}$. The null model is constructed  a symmetric form for $\boldsymbol{\hat{\Lambda}}$ while the alternative model uses a compound symmetry form. This time $\boldsymbol{\hat{D}}$ has a symmetric form for both models, and will be the same for both.


\subsubsection{Bland-Altman's blood data}
For the null model the MLE of the within-subject variance covariance matrix is given below.

\begin{equation}
\boldsymbol{\hat{\Lambda}_{Symm}} = \left( \begin{array}{cc}
    37.40 & 16.06  \\
    16.06 & 83.14  \\
    \end{array}\right)
\end{equation}
With the alternative model the MLE is as follows:

\begin{equation}
\boldsymbol{\hat{\Lambda}_{CS}} = \left( \begin{array}{cc}
    60.27  & 16.06  \\
    16.06  & 60.27  \\
    \end{array}\right)
\end{equation}

A likelihood ratio test is perform to determine which model is more suitable.
The outcome of this test is that it can be assumed that they have equal
The test statistic is the difference of the $-2$ log likelihoods; $28.617$. The $p-$value is less than $0.0001$. In this case we reject the null hypothesis that both models have the same within-subject variabilities.

%-----------------------------------------------%
\subsection{Variability test 3}
This is a test on whether both methods $A$ and $B$ have the same overall variability or not.
\begin{eqnarray}
H_{0}: \mbox{ }\sigma_{A}  = \sigma_{B} \\
H_{A}: \mbox{ }\sigma_{A}  = \sigma_{B}
\end{eqnarray}

The null model is constructed a symmetric form for both $\boldsymbol{\hat{D}}$ and $\boldsymbol{\hat{\Lambda}}$ while the alternative model uses a compound symmetry form for both.

\subsubsection{Bland-Altman's blood data}
With the null model the MLE of the within-subject variance covariance matrix is given below.

\begin{equation}
\boldsymbol{\hat{\Sigma}_{Symm}} = \left( \begin{array}{cc}
    961.38 & 801.40  \\
    801.40 & 1054.43  \\
    \end{array}\right)
\end{equation}

With the alternative model the MLE is as follows:
\begin{equation}
\boldsymbol{\hat{\Sigma}_{CS}} = \left( \begin{array}{cc}
    1007.92  & 801.65  \\
    801.65  & 1007.92  \\
    \end{array}\right)
\end{equation}

Again a likelihood ratio test is used to determine the most suitable of the two candidate models.
The test statistic is the difference of the $-2$ log likelihoods; $28.884$. The $p-$value is less than $0.0001$. We again reject the null hypothesis. Each model has a different overall variability, a foregone conclusion from the second variability test.



\subsection{Test for inter-method bias}
The inter-method bias between the two method is found to be $15.62$ , with a $p-$value of

\subsection{Correlation Test}
\begin{equation}
\boldsymbol{\hat{r}_{\Omega}}_{ii} = \left( \begin{array}{cc}
    1  & 0.7959  \\
    0.7959  & 1  \\
    \end{array}\right)
\end{equation}

The  diagonal blocks $\boldsymbol{\hat{r}_{\Omega}}_{ii}$ of the correlation matrix indicate an overall coefficient of $0.7959$.
This is less than the threshold of 0.82 that Roy recommends.

The off diagonal blocks of the overall correlation matrix $\boldsymbol{\hat{r}_{\Omega}}_{ii'}$ are
\begin{equation}
\boldsymbol{\hat{r}_{\Omega}}_{ii'} = \left( \begin{array}{cc}
    0.9611  & 0.7799  \\
    0.7799  & 0.9212  \\
    \end{array}\right).
\end{equation}

\subsection{Conclusion of procedure}
The overall conclusion of the procedure is that the two methods are not in agreement, specifically due to the within-subject variability, and the inter-method bias. The repeatability coefficients are substantially different, one being 49\% larger than the other. Additionally the overall correlation coefficient did not exceed the recommended threshold of $0.82$.

%------------------------------------------------------------------------------------%
\newpage
\section{Limits of agreement in LME models}

Limits of agreement are used extensively for assessing agreement, due to they're being intuitive and easy to use.
Necessarily their prevalence in literature has meant that they are now the best known measurement for agreement, and that any newer methodology would benefit by making reference to them.

\citet{BXC2008} uses LME models to determine the limits of agreement. Between-subject variation for method $m$ is given by $d^2_{m}$ and within-subject variation is given by $\lambda^2_{m}$.  \citet{BXC2008} remarks that for two methods $A$ and $B$, separate values of $d^2_{A}$ and $d^2_{B}$ cannot be estimated, only their average. Hence the assumption that $d_{x}= d_{y}= d$ is necessary. The between-subject variability $\boldsymbol{D}$ and within-subject variability $\boldsymbol{\Lambda}$ can be presented in matrix form,\begin{equation}
\boldsymbol{D} = \left(%
\begin{array}{cc}
   d^2_{A}& 0 \\
  0 & d^2_{B} \\
\end{array}%
\right)=\left(%
\begin{array}{cc}
   d^2& 0 \\
  0 & d^2\\
\end{array}%
\right),
\qquad \qquad
\boldsymbol{\Lambda} = \left(%
\begin{array}{cc}
   \lambda^2_{A}& 0 \\
  0 & \lambda^2_{B} \\
\end{array}%
\right).
\end{equation}

The variance for method $m$ is $d^2_{m}+\lambda^2_{m}$. Limits of agreement are determined using the standard deviation of the case-wise differences between the sets of measurements by two methods $A$ and $B$, given by
\begin{equation}
\mbox{var} (y_{A}-y_{B}) = 2d^2 + \lambda^2_{A}+ \lambda^2_{B}.
\end{equation}
Importantly the covariance terms in both variability matrices are zero, and no covariance component is present.

\citet{BXC2008} presents a data set `fat', which is a comparison of measurements of subcutaneous fat
by two observers at the Steno Diabetes Center, Copenhagen. Measurements are in millimeters
(mm). Each person is measured three times by each observer. The observations are considered to be `true' replicates.

A linear mixed effects model is formulated, and implementation through several software packages is demonstrated.
All of the necessary terms are presented in the computer output. The limits of agreement are therefore,
\begin{equation}
0.0449  \pm 1.96 \times  \sqrt{2 \times 0.0596^2 + 0.0772^2 + 0.0724^2} = (-0.220,  0.309).
\end{equation}

\citet{roy} has demonstrated a methodology whereby $d^2_{A}$ and $d^2_{B}$ can be estimated separately. Also covariance terms are present in both $\boldsymbol{D}$ and $\boldsymbol{\Lambda}$. Using Roy's methodology, the variance of the differences is
\begin{equation}
\mbox{var} (y_{iA}-y_{iB})= d^2_{A} + \lambda^2_{B} + d^2_{A} + \lambda^2_{B} - 2(d_{AB} + \lambda_{AB})
\end{equation}
All of these terms are given or determinable in computer output.
The limits of agreement can therefore be evaluated using
\begin{equation}
\bar{y_{A}}-\bar{y_{B}} \pm 1.96 \times \sqrt{ \sigma^2_{A} + \sigma^2_{B}  - 2(\sigma_{AB})}.
\end{equation}

For Carstensen's `fat' data, the limits of agreement computed using Roy's
method are consistent with the estimates given by \citet{BXC2008}; $0.044884  \pm 1.96 \times  0.1373979 = (-0.224,  0.314).$

\subsection{Linked replicates}

\citet{BXC2008} proposes the addition of an random effects term to their model when the replicates are linked. This term is used to describe the `item by replicate' interaction, which is independent of the methods. This interaction is a source of variability independent of the methods. Therefore failure to account for it will result in variability being wrongly attributed to the methods.

\citet{BXC2008} introduces a second data set; the oximetry study. This study done at the Royal Childrenï¿½s Hospital in
Melbourne to assess the agreement between co-oximetry and pulse oximetry in small babies.

In most cases, measurements were taken by both method at three different times. In some cases there are either one or two pairs of measurements, hence the data is unbalanced. \citet{BXC2008} describes many of the children as being very sick, and with very low oxygen saturations levels. Therefore it must be assumed that a biological change can occur in interim periods, and measurements are not true replicates.

\citet{BXC2008} demonstrate the necessity of accounting for linked replicated by comparing the limits of agreement from the `oximetry' data set using a model with the additional term, and one without. When the interaction is accounted for the limits of agreement are (-9.62,14.56). When the interaction is not accounted for, the limits of agreement are (-11.88,16.83). It is shown that the failure to include this additional term results in an over-estimation of the standard deviations of differences.

Limits of agreement are determined using Roy's methodology, without adding any additional terms, are are found to be consistent with the 'interaction' model; $(-9.562, 14.504 )$. Roy's methodology assumes that replicates are linked. However, following Carstensen's example, an addition interaction term is added to the implementation of Roy's model to assess the effect, the limits of agreement estimates do not change. However there is a conspicuous difference in within-subject matrices of both models (denoted $1$ and $2$ respectively);
\begin{equation}
\hat{\boldsymbol{\Lambda}}_{1}= \pmatrix{
 16.61 &	11.67\cr
11.67 & 27.65 }\qquad
\boldsymbol{\hat{\Lambda}}_{2}= \pmatrix{
    7.55 & 2.60 \cr
    2.60 & 18.59}
\end{equation}

The variance of the additional random effect in model $2$ is $3.01$.

The Akaike information criterion (AIC) for both of models are $AIC_{1} = 2304.226$ and $AIC_{2} = 2306.226$. Having a difference of AIC values of $2$ is equivalent to both models being equally as good as the other. The AIC values for
the Carstensen `unlinked' and `linked' models are $1994.66$ and $1955.48$ respectively.

The $\boldsymbol{\hat{\Lambda}}$ matrices are informative as to the difference between Carstensen's unlinked and linked models. For the oximetry data, the covariance terms (given above as 11.67 and 2.6 respectively ) are of similar magnitudes to the variance terms. Conversely for the `fat' data the covariance term ($-0.00032$) is negligible. When the interaction term is added to the model, the covariance term remains negligible. (For the `fat' data, the difference in AIC values is also $2$).

To conclude, Carstensen's models provided a rigorous way to determine limits of agreement, but don't provide for the computation of $\boldsymbol{\hat{D}}$ and $\boldsymbol{\hat{\Lambda}}$. Therefore the test's proposed by \citet{roy} can not be implemented. Conversely, accurate limits of agreement can be found using Roy's method.

Addition of the interaction term erodes the capability of Roy's methodology to compare candidate models, and therefore shall not be adopted.

(N.B. To complement the blood pressure `J vs S' analysis, the limits of agreement are $15.62 \pm 1.96 \times 20.33 = (-24.22, 55.46)$.)

%------------------------------------------------------------------------------------%
\newpage
\section{Extension of Roy's methodology}
An implementation of Roy's methodology whereby three or more methods are used is not feasible in \texttt{R} due to computational restrictions. Specifically there is a failure of \texttt{R} compiler the to reach convergence before the iteration limit is reached. This may be due to the presence of additional variables, causing the problem of non-identifiability. In the case of two variables, it is required to estimate two variance terms and four correlation terms, six in all. For the case of three variabilities, three variance terms must be estimated as well as nine correlation terms, twelve in all. In general for $n$ methods has $n + T_{n-1} + T_{n}$ variance terms, where $T_n$ is the triangular number for $n$. Hence the computational complexity quite increases substantially for every increase in $n$.

Should an implementation be feasible, further difficulty arises when interpreting the results. The fundamental question is whether two methods have close agreement so as to be interchangeable. When three methods are present in the model, the null hypothesis is that all three methods have the same variability relevant to the respective tests. The outcome of the analysis will either be that all three are interchangeable or that all three are not interchangeable.

The tests would not be informative as to whether any two of those three were interchangeable, or equivalently if one method in particular disagreed with the other two. Indeed it is easier to perform three pair-wise comparisons separately and then to combine the results.

\section{Roy's methodology for single measurements}
Roy's methodology follows from the decomposition for the covariance matrix of the response vector $y_{i}$, as presented in \citet{hamlett}. The decomposition depends on the estimation of correlation terms, which would be absent in the single measurement case. Indeed there can be no within-subject variability if there are no repeated terms for it to describe. There would only be the covariance matrix of the measurements by both methods, which doesn't require the use of LME models. To conlude, simple existing methodologies would be the correct approach where there only one measurements by each method.


\chapter{LME Estimation and Algorithms}
\section{Algorithms}
Maximum likelihood estimation is a method of obtaining estimates
of unknown parameters by optimizing a likelihood function. The ML
parameter estimates are the values of the argument that maximise
the likelihood function, i.e. the estimates that make the observed
values of the dependent variable most likely, given the
distributional assumptions

The most common iterative algorithms used for the optimization
problem in the context of LMEs are the EM algoritm, fisher scoring
algorithm and NR algorithm, which [cite:West] commends as the
preferred method.

A mixed model is an extension of the general linear models that
can specify additional random effects terms.

Parameter of the mixed model can be estimated using either ML or
REML, while the AIC and the BIC can be used as measures of
"goodness of fit" for particular models, where smaller values are
considered preferable.

%--------------------------------------------------------------------%

\newpage

\subsection{ML v REML}
(\textbf{\emph{Wikipedia}})The restricted (or residual, or reduced) maximum likelihood (REML) approach is a particular form of maximum likelihood estimation which does not base estimates on a maximum likelihood fit of all the information, but instead uses a likelihood function calculated from a transformed set of data, so that nuisance parameters have no effect.

In contrast to the earlier maximum likelihood estimation, REML can produce unbiased estimates of variance and covariance parameters.

%-----------------------------------------------------------------------------------------%
\newpage
\section{ML procedures for LME}

The maximum likelihood procedure of Hartley and Rao yields
simultaneous estimates for both the fixed effects and the random
effect, by maximising the likelihood of $\boldsymbol{y}$ with
respect to each element of $\boldsymbol{\beta}$ and
$\boldsymbol{b}$.

%-----------------------------------------------------------------------------------------%
\newpage
\section{Estimation of random effects}

Estimation of random effects for LME models in the NLME package is accomplished through use
of both EM (Expectation-Maximization) algorithms and Newton-Raphson algorithms.
\begin{itemize}
	\item EM iterations bring estimates of the parameters into the region of the optimum very quickly, but
	convergence to the optimum is slow when near the optimum.
	\item Newton-Raphson iterations are computationally intensive and can be unstable when far from the
	optimum. However, close to the optimum they converge quickly.
	\item The LME function implements a hybrid approach, using 25 EM iterations to quickly get near the
	optimum, then switching to Newton-Raphson iterations to quickly converge to the optimum. \item If
	convergence problems occur, the ``controlÂ” argument in LME can be used to change the way the
	model arrives at the optimum.
\end{itemize}


%------------------------------------------------%
\newpage
\addcontentsline{toc}{section}{Bibliography}
\bibliography{2012bib}
\chapter{New LME Notes}
\section{Linear Mixed Effects Models}

% \subsection{What are LME Models?}

% \subsection{Laird-Ware Notation}

\subsection{Why use LMEs for Method Comparison?}




The well-known ``Limits of Agreement", as developed by Bland and Altman (1986) are easily computable using the LME framework, proposed by Roy. While we will not be considering this analysis, a demonstration will be provided in the example.

Further to this, Roy(2009) demonstrates an suite of tests that can be used to determine how well two methods of measurement, in the presence of repeated measures, agree with each other.

\begin{itemize}\itemsep0.5cm
	\item No Significant inter-method bias
	\item No difference in the between-subject variabilities of the two methods
	\item No difference in the within-subject variabilities of the two methods
\end{itemize}
\newpage	

\begin{enumerate}
	\item Classical models
	\item Grouped data sets
	\item variance components
	\begin{enumerate}
		\item Fixed effects
		\item Random effects
	\end{enumerate}
\end{enumerate}

\section{Classical Models}
%http://www.spss.ch/upload/1126184451_Linear%20Mixed%20Effects%20Modeling%20in%20SPSS.pdf

%A fitted model has the form $y\;=\;X\beta+\varepsilon$, where $y$ is a vector of responses, $X$ is the fixed-effects design matrix, $\beta$ is a vector of fixed-effects parameters and $\boldsymbol{\varepsilon}}$ is a vector of residual errors.

%LAter

\subsection{With non-iid residual errors}
%spss.ch
%Growth Data Set?
The assumption may be violated in some situations. This often happens when repeated measurements are made on each 
subject. In the \textit{growth} study dataset, for example, the response variable of each subject is measured at various ages. We 
may suspect that error terms within a subject are correlated. A reasonable choice of the residual error covariance will therefore 
be a block diagonal matrix, where each block is a first-order autoregressive (AR1) covariance matrix.





\chapter{Old Notes}
\begin{enumerate}
	\item Classical models
	\item Grouped data sets
	\item variance components
	\begin{enumerate}
		\item Fixed effects
		\item Random effects
	\end{enumerate}
\end{enumerate}

\section{Classical Models}
%http://www.spss.ch/upload/1126184451_Linear%20Mixed%20Effects%20Modeling%20in%20SPSS.pdf

%A fitted model has the form $y\;=\;X\beta+\varepsilon$, where $y$ is a vector of responses, $X$ is the fixed-effects design matrix, $\beta$ is a  vector of fixed-effects parameters and $\boldsymbol{\varepsilon}}$ is a vector of residual errors.

%LAter

\subsection{With non-iid residual errors}
%spss.ch
%Growth Data Set?
The assumption may be violated in some situations. This often happens when repeated measurements are made on each 
subject. In the \textit{growth} study dataset, for example, the response variable of each subject is measured at various ages. We 
may suspect that error terms within a subject are correlated. A reasonable choice of the residual error covariance will therefore 
be a block diagonal matrix, where each block is a first-order autoregressive (AR1) covariance matrix.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Grouped Data Sets}
In modern statistical analysis , data sets have very complex
structures, such as  clustered data, repeated data and
hierarchical data (henceforth referred to as grouped data).

Repeated data considers various observations periodically taken
from the same subjects. `Before and after' measurements, as used
in paired t tests, are a well known example of repeated
measurements. Clustered data is simply the grouping of
observations according to common characteristics. For example, an
study of pupils of a school would account for the fact that they
are grouped according to their classes.

Hierarchical structures organize data into a tree-like structure,
i.e. groups within groups. Using the previous example, the pupils
would be categorized according to their years (i.e the parent
group) and then their classes (i.e the child group). This can be
extended again to multiple schools, where each school would be the
parent group of each year.

An important feature of such data sets is that there is
correlation between observations within each of the groups
\citep{Faraway}. Observations in different groups may be
independent, but any assumption that these observations within the
same group are independent is inappropriate . Consequently
\citet{Demi} states that there is two sources of variations to be
considered, `within groups' and `between groups'.

%======================================================================================= %
\newpage
\section{Grouped Data Sets}
In modern statistical analysis , data sets have very complex
structures, such as  clustered data, repeated data and
hierarchical data (henceforth referred to as grouped data).

Repeated data considers various observations periodically taken
from the same subjects. `Before and after' measurements, as used
in paired t tests, are a well known example of repeated
measurements. Clustered data is simply the grouping of
observations according to common characteristics. For example, an
study of pupils of a school would account for the fact that they
are grouped according to their classes.

Hierarchical structures organize data into a tree-like structure,
i.e. groups within groups. Using the previous example, the pupils
would be categorized according to their years (i.e the parent
group) and then their classes (i.e the child group). This can be
extended again to multiple schools, where each school would be the
parent group of each year.

An important feature of such data sets is that there is
correlation between observations within each of the groups
\citep{Faraway}. Observations in different groups may be
independent, but any assumption that these observations within the
same group are independent is inappropriate . Consequently
\citet{Demi} states that there is two sources of variations to be
considered, `within groups' and `between groups'.


\section{Laird Ware Formulation}
\begin{equation}
\boldsymbol{y_{i}} = \boldsymbol{X_{i}\beta}  + \boldsymbol{Z_{i}b_{i}} + \boldsymbol{\epsilon_{i}}, \qquad i=1,\dots,85
\end{equation}
\begin{eqnarray}
\boldsymbol{Z_{i}} \sim \mathcal{N}(\boldsymbol{0,\Psi}),\qquad
\boldsymbol{\epsilon_{i}} \sim \mathcal{N}(\boldsymbol{0,\sigma^2\Lambda})
\end{eqnarray}

\section{Normal linear mixed models}

The standard linear mixed effects model specifies
\begin{equation}
y = X \beta + Zb + \epsilon , 
\label{lme:Model}
\end{equation}
where $y$ is a vector of $N$ observable random variables, $\beta$ is a vector of $p$ unknown parameters having fixed values (fixed effects), $X$ and $Z$ are $N \times p$ and $N \times q$ known matrices, and $b$ and $\epsilon$  are vectors of $q$ and $N,$ respectively, unobservable random variables (random effects) such that $\mathrm{E}(b)=0, \ \mathrm{E}(\epsilon)=0$
and
\[
\mathrm{var}
\pmatrix{
	b \cr
	\epsilon }  =
\pmatrix{
	D & 0 \cr
	0 & \Sigma }
\]
where $D$ and $\Sigma$ are positive definite matrices parameterized by an unknown variance component parameter vector $ \theta.$


\subsubsection*{Henderson's equations}

\cite{Henderson:1950} made the (ad-hoc) distributional assumptions $y|b \sim \mathrm{N} (X \beta + Zb, \Sigma)$ and $b \sim \mathrm{N}(0,D),$ and proceeded to maximize the joint density of $y$ and $b$
\begin{equation}
\left|
\pmatrix{
	D & 0 \cr
	0 & \Sigma }
\right|^{-\frac{1}{2}}
\exp
\left\{ -\frac{1}{2}
\pmatrix{
	b \cr
	y - X \beta -Zb
}^\prime
\pmatrix{
	D & 0 \cr
	0 & \Sigma }^{-1}
\pmatrix{
	b \cr
	y - X \beta -Zb
}
\right\},
\label{u&beta:JointDensity}
\end{equation}
with respect to $\beta$ and $b,$ which ultimately requires minimizing the criterion
\begin{equation}
(y - X \beta -Zb)'\Sigma^{-1}(y - X \beta -Zb) + b^\prime D^{-1}b. 
\label{Henderson:Criterion}
\end{equation}
This leads to the solutions
\begin{equation}
\pmatrix{
	X^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}Z
	\cr
	Z^\prime\Sigma^{-1}X & X^\prime\Sigma^{-1}X + D^{-1}
}
\pmatrix{
	\beta \cr
	b
}
=
\pmatrix{
	X^\prime\Sigma^{-1}y \cr
	Z^\prime\Sigma^{-1}y
}.
\label{Henderson:Equations}
\end{equation}
\cite{Robi:BLUP:1991} points out that although \cite{Henderson:1950} initially referred to the estimates $\hat{\beta}$ and $\hat{b}$ from (\ref{Henderson:Equations}) as ``joint maximum likelihood estimates" \cite{Henderson:1973} later advised that these estimates should not be referred to as ``maximum likelihood" as the function being maximized in (\ref{Henderson:Criterion}) is a joint density rather than a likelihood function.

\subsubsection*{Estimation of the fixed parameters}

The vector $y$ has marginal density $y \sim \mathrm{N}(X \beta,V),$ where $V = \Sigma + ZDZ^\prime$ is specified through the variance component parameters $\theta.$ The log-likelihood of the fixed parameters $(\beta, \theta)$ is
\begin{equation}
\ell (\beta, \theta|y) =
-\frac{1}{2} \log |V| -\frac{1}{2}(y -
X \beta)'V^{-1}(y -
X \beta), \label{Likelihood:MarginalModel}
\end{equation}
and for fixed $\theta$ the estimate $\hat{\beta}$ of $\beta$ is obtained as the solution of
\begin{equation}
(X^\prime V^{-1}X) {\beta} = X^\prime V^{-1}y.
\label{mle:beta:hat}
\end{equation} 

Maximum likelihood and restricted maximum likelihood have become the most common strategies for estimating the variance component parameter $\theta.$ Substituting $\hat{\beta}$ from (\ref{mle:beta:hat}) into $\ell(\beta, \theta|y)$ from (\ref{Likelihood:MarginalModel}) returns the \emph{profile} log-likelihood
\begin{eqnarray*}
	\ell_P(\theta \mid y) &=& \ell(\hat{\beta}, \theta \mid y) \\ 
	&=& -\frac{1}{2} \log |V| -\frac{1}{2}(y - X \hat{\beta})'V^{-1}(y - X \hat{\beta})
\end{eqnarray*}
of the variance parameter $\theta.$ Estimates of the parameters $\theta$ specifying $V$ can be found by maximizing $\ell_P(\theta \mid y)$ over $\theta.$ In practice the \emph{restricted} log-likelihood
\[
\ell_R(\theta \mid y) =
\ell_P(\theta \mid y) -\frac{1}{2} \log |X^\prime VX |
\]
is preferred. This approach is based on maximizing the likelihood of linear combinations of $y$ that do not depend on $\beta,$ and in this way takes into account the estimation of $\beta.$


\subsubsection*{Estimation of the random effects}

The established approach for estimating the random effects is to use the best linear predictor of $b$ from $y,$ which for a given $\beta$ equals $DZ^\prime V^{-1}(y - X \beta).$ In practice $\beta$ is replaced by an estimator such as $\hat{\beta}$ from (\ref{mle:beta:hat}) so that $\hat{b} = DZ^\prime V^{-1}(y - X \hat{\beta}).$ Pre-multiplying by the appropriate matrices it is straightforward to show that these estimates $\hat{\beta}$ and $\hat{b}$ satisfy the equations in (\ref{Henderson:Equations}).


\subsubsection*{The extended likelihood}

The desire to have an entirely likelihood-based justification for estimates of random effects has motivated \citet[page 429]{Pawi:in:2001} to define the \emph{extended likelihood}. He remarks ``In mixed effects modelling the extended likelihood has been called \emph{h-likelihood} (for hierarchical  likelihood) by \cite{Lee:Neld:hier:1996}, while in smoothing literature it is known as the \emph{penalized likelihood} (e.g.\ \citeauthor{Gree:Silv:nonp:1994} \citeyear{Gree:Silv:nonp:1994})." The extended likelihood can be written $L(\beta,\theta,b|y) = p(y|b;\beta,\theta) p(b;\theta)$ and adopting the same distributional assumptions used by \cite{Henderson:1950} yields the log-likelihood function
\begin{eqnarray*}
	\ell_h(\beta,\theta,b|y)
	& = \displaystyle -\frac{1}{2} \left\{ \log|\Sigma| + (y - X \beta -Zb)'\Sigma^{-1}( y - X \beta -Zb) \right.\\
	&  \hspace{0.5in} \left. + \log|D| + b^\prime D^{-1}b \right\}.
\end{eqnarray*}
Given $\theta$, differentiating with respect to $\beta$ and $b$ returns Henderson's equations in (\ref{Henderson:Equations}).


Henderson's equations in (\ref{Henderson:Equations}) can be rewritten $( T^\prime W^{-1} T ) \delta = T^\prime W^{-1} y_{a} $ using
\[
\delta = \pmatrix{\beta \cr b},
\ y_{a} = \pmatrix{
	y \cr \psi
},
\ T = \pmatrix{
	X & Z  \cr
	0 & I
},
\ \textrm{and} \ W = \pmatrix{
	\Sigma & 0  \cr
	0 &  D },
\]
where \cite{Lee:Neld:Pawi:2006} describe $\psi = 0$ as quasi-data with mean $\mathrm{E}(\psi) = b.$ Their formulation suggests that the joint estimation of the coefficients $\beta$ and $b$ of the linear mixed effects model in (\ref{lme:Model}) can be derived via a classical augmented general linear model $y_{a} = T\delta + \varepsilon$ where $\mathrm{E}(\varepsilon) = 0$ and $\mathrm{var}(\varepsilon) = W,$ with \emph{both} $\beta$ and $b$ appearing as fixed parameters.

\section{Note 2: Model terms}
It is important to note the following characteristics of this model.
\begin{itemize}
	\item Let the number of replicate measurements on each item $i$ for both methods be $n_i$, hence $2 \times n_i$ responses. However, it is assumed that there may be a different number of replicates made for different items. Let the maximum number of replicates be $p$. An item will have up to $2p$ measurements, i.e. $\max(n_{i}) = 2p$.
	
	% \item $\boldsymbol{y}_i$ is the $2n_i \times 1$ response vector for measurements on the $i-$th item.
	% \item $\boldsymbol{X}_i$ is the $2n_i \times  3$ model matrix for the fixed effects for observations on item $i$.
	% \item $\boldsymbol{\beta}$ is the $3 \times  1$ vector of fixed-effect coefficients, one for the true value for item $i$, and one effect each for both methods.
	
	\item Later on $\boldsymbol{X}_i$ will be reduced to a $2 \times 1$ matrix, to allow estimation of terms. This is due to a shortage of rank. The fixed effects vector can be modified accordingly.
	\item $\boldsymbol{Z}_i$ is the $2n_i \times  2$ model matrix for the random effects for measurement methods on item $i$.
	\item $\boldsymbol{b}_i$ is the $2 \times  1$ vector of random-effect coefficients on item $i$, one for each method.
	\item $\boldsymbol{\epsilon}$  is the $2n_i \times  1$ vector of residuals for measurements on item $i$.
	\item $\boldsymbol{G}$ is the $2 \times  2$ covariance matrix for the random effects.
	\item $\boldsymbol{R}_i$ is the $2n_i \times  2n_i$ covariance matrix for the residuals on item $i$.
	\item The expected value is given as $\mbox{E}(\boldsymbol{y}_i) = \boldsymbol{X}_i\boldsymbol{\beta}.$ \citep{hamlett}
	\item The variance of the response vector is given by $\mbox{Var}(\boldsymbol{y}_i)  = \boldsymbol{Z}_i \boldsymbol{G} \boldsymbol{Z}_i^{\prime} + \boldsymbol{R}_i$ \citep{hamlett}.
\end{itemize}
\addcontentsline{toc}{section}{Bibliography}

\bibliography{transferbib}
\end{document}
