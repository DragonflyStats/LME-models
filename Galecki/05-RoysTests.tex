%---------------------------------------------------------------------------------%

\documentclass[12pt, a4paper]{article}
\usepackage{array} % and/or
\usepackage{longtable} % and/or
\usepackage{colortab} % or
\usepackage{colortbl}
\usepackage{arydshln}
\usepackage{epsfig}
\usepackage{subfigure}
%\usepackage{amscd}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsthm, amsmath}
%\usepackage[dvips]{graphicx}
\usepackage{natbib}
\bibliographystyle{chicago}
\usepackage{vmargin}
% left top textwidth textheight headheight
% headsep footheight footskip
\setmargins{3.0cm}{2.5cm}{15.5 cm}{22cm}{0.5cm}{0cm}{1cm}{1cm}
\renewcommand{\baselinestretch}{1.5}
\pagenumbering{arabic}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{ill}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{axiom}{Axiom}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{notation}{Notation}
\theoremstyle{remark}
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\renewcommand{\thenotation}{}
\renewcommand{\thetable}{\thesection.\arabic{table}}
\renewcommand{\thefigure}{\thesection.\arabic{figure}}
\title{Research notes: linear mixed effects models}
\author{ } \date{ }


\begin{document}
	\author{Kevin O'Brien}
	\title{Updating techniques for LME models}
	
	\addcontentsline{toc}{section}{Bibliography}

\subsection{Roy's method}


Roy proposes a novel method using the LME model with Kronecker product covariance structure in a doubly multivariate set-up to assess the agreement between a new method and an established method with unbalanced data and with unequal replications for different subjects \citep{Roy}.

Using Roy's method, four candidate models are constructed, each differing by constraints applied to the variance covariance matrices. In addition to computing the inter-method bias, three significance tests are carried out on the respective formulations to make a judgement on whether or not two methods are in agreement.

%---------------------------------------------------------------------------------%
\subsection{Hypothesis Testing}
The formulation presented above usefully facilitates a series of
significance tests that advise as to how well the two methods
agree. These tests are as follows:
\begin{itemize}
\item A formal test for the equality of between-item variances,
\item A formal test for the equality of within-item variances,
\item A formal test for the equality of overall variances.
\end{itemize}
These tests are complemented by the ability to consider the inter-method bias and the overall correlation coefficient. Two methods can be considered to be in agreement if criteria based upon these methodologies are met. Additionally Roy makes reference to the overall correlation coefficient of the two methods, which is determinable from variance estimates.




\section{Introduction}

\citet{roy} uses an approach based on linear mixed effects (LME) models for the purpose of comparing the agreement between two methods of measurement, where replicate measurements on items (often individuals) by both methods are available. She provides three tests of hypothesis appropriate for evaluating the agreement between the two methods of measurement under this sampling scheme. These tests consider null hypotheses that assume: absence of inter-method bias; equality of between-subject variabilities of the two methods; equality of within-subject variabilities of the two methods. By inter-method bias we mean that a systematic difference exists between observations recorded by the two methods. Differences in between-subject variabilities of the two methods arise when one method is yielding average response levels for individuals than are more variable than the average response levels for the same sample of individuals taken by the other method.  Differences in within-subject variabilities of the two methods arise when one method is yielding responses for an individual than are more variable than the responses for this same individual taken by the other method. The two methods of measurement can be considered to agree, and subsequently can be used interchangeably, if all three null hypotheses are true.

\bigskip

Let $y_{mir} $ denote the $r$th replicate measurement on the $i$th item by the $m$th method, where $m=1,2$ ; $i=1,\ldots,N;$ and $r = 1,\ldots,n_i.$ When the design is balanced and there is no ambiguity we can set $n_i=n.$ The LME model underpinning Roy's approach can be written
\begin{equation}\label{Roy-model}
y_{mir} = \beta_{0} + \beta_{m} + b_{mi} + \epsilon_{mir}.
\end{equation}
Here $\beta_0$ and $\beta_m$ are fixed-effect terms representing, respectively, a model intercept and an overall effect for method $m.$ The model can be reparameterized by gathering the $\beta$ terms together into (fixed effect) intercept terms $\alpha_m=\beta_0+\beta_m.$ The $b_{1i}$ and $b_{2i}$ terms are correlated random effect parameters having $\mathrm{E}(b_{mi})=0$ with $\mathrm{Var}(b_{mi})=g^2_m$ and $\mathrm{Cov}(b_{1i}, b_{2 i})=g_{12}.$ The random error term for each response is denoted $\epsilon_{mir}$ having $\mathrm{E}(\epsilon_{mir})=0$, $\mathrm{Var}(\epsilon_{mir})=\sigma^2_m$, $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir})=\sigma_{12}$, $\mathrm{Cov}(\epsilon_{mir}, \epsilon_{mir^\prime})= 0$ and $\mathrm{Cov}(\epsilon_{1ir}, \epsilon_{2 ir^\prime})= 0.$ Additionally these parameter are assumed to have Gaussian distribution. Two methods of measurement are in complete agreement if the null hypotheses $\mathrm{H}_1\colon \alpha_1 = \alpha_2$ and $\mathrm{H}_2\colon \sigma^2_1 = \sigma^2_2 $ and $\mathrm{H}_3\colon g^2_1= g^2_2$ hold simultaneously. \citet{roy} uses a Bonferroni correction to control the familywise error rate for tests of $\{\mathrm{H}_1, \mathrm{H}_2, \mathrm{H}_3\}$ and account for difficulties arising due to multiple testing. Additionally, Roy combines $\mathrm{H}_2$ and $\mathrm{H}_3$ into a single testable hypothesis $\mathrm{H}_4\colon \omega^2_1=\omega^2_2,$ where $\omega^2_m = \sigma^2_m + g^2_m$ represent the overall variability of method $m.$
%Disagreement in overall variability may be caused by different between-item variabilities, by different within-item variabilities, or by both.

%If the exact cause of disagreement between the two methods is not of interest, then the overall variability test $H_4$ %is an alternative to testing $H_2$ and $H_3$ separately.

\bigskip

\cite{BXC2008} also use a LME model for the purpose of comparing two methods of measurement where replicate measurements are available on each item. Their interest lies in generalizing the popular limits-of-agreement (LOA) methodology advocated by \citet{BA86} to take proper cognizance of the replicate measurements. \citet{BXC2008} demonstrate statistical flaws with two approaches proposed by \citet{BA99} for the purpose of calculating the variance of the inter-method bias when replicate measurements are available. Instead, they recommend a fitted mixed effects model to obtain appropriate estimates for the variance of the inter-method bias. As their interest mainly lies in extending the Bland-Altman methodology, other formal tests are not considered.

\bigskip

\citet{BXC2008} develop their model from a standard two-way analysis of variance model, reformulated for the case of replicate measurements, with random effects terms specified as appropriate.
Their model can be written as
%describing $y_{mir} $, again the $r$th replicate measurement on the $i$th item by the $m$th method ($m=1,2,$ %$i=1,\ldots,N,$ and $r = 1,\ldots,n$),

\begin{equation}\label{BXC-model}
y_{mir}  = \alpha_{m} + \mu_{i} + a_{ir} + c_{mi} + \varepsilon_{mir}.
\end{equation}
The fixed effects $\alpha_{m}$ and $\mu_{i}$ represent the intercept for method $m$ and the `true value' for item $i$ respectively. The random-effect terms comprise an item-by-replicate interaction term $a_{ir} \sim \mathcal{N}(0,\varsigma^{2})$, a method-by-item interaction term $c_{mi} \sim \mathcal{N}(0,\tau^{2}_{m}),$ and model error terms $\varepsilon_{mir} \sim \mathcal{N}(0,\varphi^{2}_{m}).$ All random-effect terms are assumed to be independent. For the case when replicate measurements are assumed to be exchangeable for item $i$, $a_{ir}$ can be removed. The model expressed in (2) describes measurements by $m$ methods, where $m = \{1,2,3\ldots\}$. Based on the model expressed in (2), \citet{BXC2008} compute the limits of agreement as
\[
\alpha_1 - \alpha_2 \pm 2 \sqrt{ \tau^2_1 +  \tau^2_2 +  \varphi^2_1 +  \varphi^2_2 }
\]
\citet{BXC2008} notes that, for $m=2$,  separate estimates of $\tau^2_m$ can not be obtained. To overcome this, the assumption of equality, i.e. $\tau^2_1 = \tau^2_2$ is required.

%%---Comparative Complexity
There is a substantial difference in the number of fixed parameters used by the respective models; the model in (\ref{Roy-model}) requires two fixed effect parameters, i.e. the means of the two methods, for any number of items $N$, whereas the model in (\ref{BXC-model}) requires $N+2$ fixed effects.

Allocating fixed effects to each item $i$ by (\ref{BXC-model}) accords with earlier work on comparing methods of measurement, such as \citet{Grubbs48}. However allocation of fixed effects in ANOVA models suggests that the group of items is itself of particular interest, rather than as a representative sample used of the overall population. However this approach seems contrary to the purpose of LOAs as a prediction interval for a population of items. Conversely, \citet{roy}
uses a more intuitive approach, treating the observations as a random sample population, and allocating random effects accordingly.

\newpage
\newpage

\section{Roy's Hypotheses Tests}

In order to express Roy's LME model in matrix notation we gather all $2n_i$ observations specific to item $i$ into a single vector $\boldsymbol{y}_{i} = (y_{1i1},y_{2i1},y_{1i2},\ldots,y_{mir},\ldots,y_{1in_{i}},y_{2in_{i}})^\prime.$ The LME model can be written
\[
\boldsymbol{y_{i}} = \boldsymbol{X_{i}\beta} + \boldsymbol{Z_{i}b_{i}} + \boldsymbol{\epsilon_{i}},
\]
where $\boldsymbol{\beta}=(\beta_0,\beta_1,\beta_2)^\prime$ is a vector of fixed effects, and $\boldsymbol{X}_i$ is a corresponding $2n_i\times 3$ design matrix for the fixed effects. The random effects are expressed in the vector $\boldsymbol{b}=(b_1,b_2)^\prime$, with $\boldsymbol{Z}_i$ the corresponding $2n_i\times 2$ design matrix. The vector $\boldsymbol{\epsilon}_i$ is a $2n_i\times 1$ vector of residual terms. Random effects and residuals are assumed to be independent of each other.

The random effects are assumed to be distributed as $\boldsymbol{b}_i \sim \mathcal{N}_2(0,\boldsymbol{G})$. The between-item variance covariance matrix $\boldsymbol{G}$ is constructed as follows:
\[ \boldsymbol{G} =\left(
            \begin{array}{cc}
              g^2_1  & g_{12} \\
              g_{12} & g^2_2 \\
            \end{array}
          \right) \]

The matrix of random errors $\boldsymbol{\epsilon}_i$ is distributed as $\mathcal{N}_2(0,\boldsymbol{R}_i)$.
\citet{hamlett} shows that the variance covariance matrix for the residuals(i.e. the within-item sources of variation between both methods) can be expressed as the Kroneckor product of an $n_i \times n_i$ identity matrix and the partial within-item variance covariance matrix $\boldsymbol{\Sigma}$, i.e. $\boldsymbol{R}_{i} = \boldsymbol{I}_{n_{i}} \otimes \boldsymbol{\Sigma}$.
\[
\boldsymbol{\Sigma} = \left( \begin{array}{cc}
  \sigma^2_{1} & \sigma_{12} \\
  \sigma_{12} & \sigma^2_{2} \\
\end{array}\right),
\]
where $\sigma^2_{1}$ and $\sigma^2_{2}$ are the within-subject variances of the respective methods, and $\sigma_{12}$ is the within-item covariance between the two methods. The within-item variance covariance matrix $\boldsymbol{\Sigma}$ is assumed to be the same for all replications. Computational analysis of linear mixed effects models allow for the explicit analysis of both $\boldsymbol{G}$ and $\boldsymbol{R_i}$.

For expository purposes consider the case where each item provides three replicate measurements by each method. In matrix form the model has the structure
\[
\boldsymbol{y}_{i} =
%---Design Matrix X ----%
\left(\begin{array}{ccc}
 1 & 1 & 0 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \\
 1 & 0 & 1 \\ 1 & 1 & 0 \\ 1 & 0 & 1 \\
\end{array}\right)
%---FE Matrix----%
\left(\begin{array}{c}
 \beta_0 \\ \beta_1 \\ \beta_2 \\
\end{array}\right)
+
%---Design Matrix Z----%
\left(\begin{array}{cc}
1 & 0 \\0 & 1 \\1 & 0 \\0 & 1 \\0 & 1 \\\end{array}
\right)
%---RE Matrix----%
\left(\begin{array}{c}
b_{1i} \\   b_{2i} \\
\end{array}\right)
+
%------Errors Vector---%
\left( \begin{array}{c}
\epsilon_{1i1} \\\epsilon_{2i1} \\\epsilon_{1i2} \\ \epsilon_{2i2} \\\epsilon_{1i3} \\\epsilon_{2i3} \\
\end{array}\right).
\]
The between-item variance covariance $\boldsymbol{G}$ is as before, while the within-item variance covariance is given as
%------Specification of within item VC matrix R---%
\[
\boldsymbol{R}_i = \left(
\begin{array}{cc:cc:cc}
  \sigma^2_{1} & \sigma_{12} & 0 & 0 & 0 & 0 \\
  \sigma_{12} & \sigma^2_{2} & 0 & 0 & 0 & 0 \\\hdashline
  0 & 0 & \sigma^2_{1} & \sigma_{12} & 0 & 0 \\
  0 & 0 & \sigma_{12} & \sigma^2_{2} & 0 & 0 \\\hdashline
  0 & 0 & 0 & 0 & \sigma^2_{1} & \sigma_{12} \\
  0 & 0 & 0 & 0 & \sigma_{12} & \sigma^2_{2} \\
\end{array} \right)
\]

The overall variability between the two methods is the sum of between-item variability
$\boldsymbol{G}$ and partial within-item variability $\boldsymbol{\Sigma}$. \citet{roy} denotes the overall variability as ${\mbox{Block - }\boldsymbol \Omega_{i}}$. The overall variation for methods $1$ and $2$ are given by

%------Overall variability in terms of G and R ----%
\begin{equation}
\left(\begin{array}{cc}
              \omega^2_1  & \omega_{12} \\
              \omega_{12} & \omega^2_2 \\
       \end{array}  \right)
 =
\left(\begin{array}{cc}
              g^2_1  & g_{12} \\
              g_{12} & g^2_2 \\
\end{array} \right)
+
\left( \begin{array}{cc}
              \sigma^2_1  & \sigma_{12} \\
              \sigma_{12} & \sigma^2_2 \\
\end{array}\right)
\end{equation}
%------------------------------------------------------------------------%
\newpage
\subsection{Roy's hypothesis tests}
% Three hypothesis tests follow from this equation.
The presence of an inter-method bias is the source of disagreement between two methods of measurement that is most easily identified. As the first in a series of hypothesis tests, \citet{roy} presents a formal test for inter-method bias. With the null and alternative hypothesis denoted $H_1$ and $K_1$ respectively, this test is formulated as
\begin{eqnarray*}
	\operatorname{H_1} : \mu_1 = \mu_2 ,\\
	\operatorname{K_1} : \mu_1 \neq \mu_2.
\end{eqnarray*}

Lack of agreement can also arise if there is a disagreement in overall variabilities. This lack of agreement may be due to differing between-item variabilities, differing within-item variabilities, or both. The formulation previously presented usefully facilitates a series of significance tests that assess if and where such differences arise. Roy allows for a formal test of each. These tests are comprised of a formal test for the equality of between-item variances,
\begin{eqnarray*}
	\operatorname{H_2} : g^2_1 = g^2_2 \\
	\operatorname{K_2} : g^2_1 \neq g^2_2
\end{eqnarray*}
and a formal test for the equality of within-item variances.
\begin{eqnarray*}
	\operatorname{H_3} : \sigma^2_1 = \sigma^2_2 \\
	\operatorname{K_3} : \sigma^2_1 \neq \sigma^2_2
\end{eqnarray*}
A formal test for the equality of overall variances is also presented.
\begin{eqnarray*}
	\operatorname{H_4} : \omega^2_1 = \omega^2_2 \\
	\operatorname{K_4} : \omega^2_1 \neq \omega^2_2
\end{eqnarray*}

These tests are complemented by the ability to the overall correlation coefficient of the two methods, which is determinable from variance estimates. Two methods can be considered to be in agreement if criteria based upon these tests are met. Inference for inter-method bias follows from well-established methods and, as such, will only be noted when describing examples.

Conversely, the tests of variability required detailed explanation. Each test is performed by fitting two candidate models, according with the null and alternative hypothesis respectively. The distinction between the models arise in the specification in one, or both, of the variance-covariance matrices. % A likelihood ratio test can then be used to compare these respective fits.



\subsection{Variance Covariance Matrices }

Under Roy's model, random effects are defined using a bivariate normal distribution. Consequently, the variance-covariance structures can be described using $2 \times 2$  matrices. A discussion of the various structures a variance-covariance matrix can be specified under is required before progressing. The following structures are relevant: the identity structure, the compound symmetric structure and the symmetric structure.

The identity structure is simply an abstraction of the identity matrix. The compound symmetric structure and symmetric structure can be described with reference to the following matrix (here in the context of the overall covariance Block-$\boldsymbol{\Omega}_i$, but equally applicable to the component variabilities $\boldsymbol{G}$ and $\boldsymbol{\Sigma}$);

\[\left( \begin{array}{cc}
              \omega^2_1  & \omega_{12} \\
              \omega_{12} & \omega^2_2 \\
\end{array}\right) \]

Symmetric structure requires the equality of all the diagonal terms, hence $\omega^2_1 = \omega^2_2$. Conversely compound symmetry make no such constraint on the diagonal elements. Under the identity structure, $\omega_{12} = 0$.
A comparison of a model fitted using symmetric structure with that of a model fitted using the compound symmetric structure is equivalent to a test of the equality of variance.


%In the presented example, it is shown that Roy's LOAs are lower than those of (\ref{BXC-model}), when covariance between methods is present.


\newpage
\bibliography{DB-txfrbib}
\end{document}


%-----------------------------------------------------------------------------------%


\newpage
\subsection{Remarks on the Multivariate Normal Distribution}

Diligence is required when considering the models. Carstensen specifies his models in terms of the univariate normal distribution. Roy's model is specified using the bivariate normal distribution.
This gives rises to a key difference between the two model, in that a bivariate model accounts for covariance between the variables of interest.
The multivariate normal distribution of a $k$-dimensional random vector $X = [X_1, X_2, \ldots, X_k]$
can be written in the following notation:
\[
X\ \sim\ \mathcal{N}(\mu,\, \Sigma),
\]
or to make it explicitly known that $X$ is $k$-dimensional,
\[
X\ \sim\ \mathcal{N}_k(\mu,\, \Sigma).
\]
with $k$-dimensional mean vector
\[ \mu = [ \operatorname{E}[X_1], \operatorname{E}[X_2], \ldots, \operatorname{E}[X_k]] \]
and $k \times k$ covariance matrix
\[ \Sigma = [\operatorname{Cov}[X_i, X_j]], \; i=1,2,\ldots,k; \; j=1,2,\ldots,k \]

\bigskip

\begin{enumerate}
\item Univariate Normal Distribution

\[
    X\ \sim\ \mathcal{N}(\mu,\, \sigma^2),
\]

\item Bivariate Normal Distribution

\begin{itemize}
\item[(a)] \[  X\ \sim\ \mathcal{N}_2(\mu,\, \Sigma), \vspace{1cm}\]
\item[(b)] \[    \mu = \begin{pmatrix} \mu_x \\ \mu_y \end{pmatrix}, \quad
    \Sigma = \begin{pmatrix} \sigma_x^2 & \rho \sigma_x \sigma_y \\
                             \rho \sigma_x \sigma_y  & \sigma_y^2 \end{pmatrix}.\]
\end{itemize}
\end{enumerate}
\newpage

\subsection{Note 1: Coefficient of Repeatability}
The coefficient of repeatability is a measure of how well a
measurement method agrees with itself over replicate measurements
\citep{BA99}. Once the within-item variability is known, the
computation of the coefficients of repeatability for both methods
is straightforward.


\subsection{Note 2: Carstensen model in the single measurement case}
\citet{BXC2004} presents a model to describe the relationship between a value of measurement and its real value.
The non-replicate case is considered first, as it is the context of the Bland-Altman plots.
This model assumes that inter-method bias is the only difference between the two methods.


\begin{equation}
y_{mi}  = \alpha_{m} + \mu_{i} + e_{mi} \qquad  e_{mi} \sim \mathcal{N}(0,\sigma^{2}_{m})
\end{equation}

The differences are expressed as $d_{i} = y_{1i} - y_{2i}$.

For the replicate case, an interaction term $c$ is added to the model, with an associated variance component.




\subsection{Note 3: Model terms}
It is important to note the following characteristics of this model.
\begin{itemize}
\item Let the number of replicate measurements on each item $i$ for both methods be $n_i$, hence $2 \times n_i$ responses. However, it is assumed that there may be a different number of replicates made for different items. Let the maximum number of replicates be $p$. An item will have up to $2p$ measurements, i.e. $\max(n_{i}) = 2p$.

% \item $\boldsymbol{y}_i$ is the $2n_i \times 1$ response vector for measurements on the $i-$th item.
% \item $\boldsymbol{X}_i$ is the $2n_i \times  3$ model matrix for the fixed effects for observations on item $i$.
% \item $\boldsymbol{\beta}$ is the $3 \times  1$ vector of fixed-effect coefficients, one for the true value for item $i$, and one effect each for both methods.

\item Later on $\boldsymbol{X}_i$ will be reduced to a $2 \times 1$ matrix, to allow estimation of terms. This is due to a shortage of rank. The fixed effects vector can be modified accordingly.
\item $\boldsymbol{Z}_i$ is the $2n_i \times  2$ model matrix for the random effects for measurement methods on item $i$.
\item $\boldsymbol{b}_i$ is the $2 \times  1$ vector of random-effect coefficients on item $i$, one for each method.
\item $\boldsymbol{\epsilon}$  is the $2n_i \times  1$ vector of residuals for measurements on item $i$.
\item $\boldsymbol{G}$ is the $2 \times  2$ covariance matrix for the random effects.
\item $\boldsymbol{R}_i$ is the $2n_i \times  2n_i$ covariance matrix for the residuals on item $i$.
\item The expected value is given as $\mbox{E}(\boldsymbol{y}_i) = \boldsymbol{X}_i\boldsymbol{\beta}.$ \citep{hamlett}
\item The variance of the response vector is given by $\mbox{Var}(\boldsymbol{y}_i)  = \boldsymbol{Z}_i \boldsymbol{G} \boldsymbol{Z}_i^{\prime} + \boldsymbol{R}_i$ \citep{hamlett}.
\end{itemize}
\newpage




%---Carstensen's limits of agreement
%---The between item variances are not individually computed. An estimate for their sum is used.
%---The within item variances are indivdually specified.
%---Carstensen remarks upon this in his book (page 61), saying that it is "not often used".
%---The Carstensen model does not include covariance terms for either VC matrices.
%---Some of Carstensens estimates are presented, but not extractable, from R code, so calculations have to be done by %---hand.
%--Importantly, estimates required to calculate the limits of agreement are not extractable, and therefore the calculation must be done by hand.
%---All of Roys stimates are  extractable from R code, so automatic compuation can be implemented
%---When there is negligible covariance between the two methods, Roys LoA and Carstensen's LoA are roughly the same.
%---When there is covariance between the two methods, Roy's LoA and Carstensen's LoA differ, Roys usually narrower.


%%---Estimability of Tau
%When only two methods are compared, \citet{BXC2008} notes that separate estimates of $\tau^2_m$ can not be obtained %due to the model over-specification. To overcome this, the assumption of equality, i.e. $\tau^2_1 = \tau^2_2$, is %required.

%With regards to the specification of the variance terms, Carstensen  remarks that using their approach is common, %remarking that \emph{ The only slightly non-standard (meaning ``not often used") feature is the differing residual %variances between methods }\citep{bxc2010}.



%\chapter{Limits of Agreement}

%\section{Modelling Agreement with LME Models}

% Carstensen pages 22-23


Roys uses and LME model approach to provide a set of formal tests for method comparison studies.\\

Four candidates models are fitted to the data.\\

These models are similar to one another, but for the imposition of equality constraints.\\

These tests are the pairwise comparison of candidate models, one formulated without constraints, the other with a constraint.\\


Roy's model uses fixed effects $\beta_0 + \beta_1$ and $\beta_0 + \beta_1$ to specify the mean of all observationsby \\ methods 1 and 2 respectively.


This model includes a method by item interaction term.\\

Carstensen presents two models. One for the case where the replicates, and a second for when they are linked.\\
Carstensen's model does not take into account either between-item or within-item covariance between methods.\\
In the presented example, it is shown that Roy's LoAs are lower than those of Carstensen.


\[\left(\begin{array}{cc}
                \omega^1_2  & 0 \\
              0 & \omega^2_2 \\
            \end{array}  \right)
            =  \left(
            \begin{array}{cc}
              \tau^2  & 0 \\
              0 & \tau^2 \\
            \end{array} \right)+
            \left(
            \begin{array}{cc}
              \sigma^2_1  & 0 \\
              0 & \sigma^2_2 \\
            \end{array}\right)
\]







%-----------------------------------------------------------------------------------%

\subsection{Computation of limits of agreement }


Further to \citet{BA86}, the computation of the limits of agreement follows from the intermethod bias, and the variance of the difference of measurements. The computation of the inter-method bias is a straightforward subtraction calculation. The variance of differences is easily computable from the variance estimates in the ${\mbox{Block - }\boldsymbol \Omega_{i}}$ matrix, i.e.
\[
% Check this
\operatorname{Var}(y_1 - y_2) = \sqrt{ \omega^2_1 + \omega^2_2 - 2\omega_{12}}.
\]

\citet{BXC2008} also presents a methodology to compute the limits of agreement based on LME models. In many cases the limits of agreement derived from this method accord with those to Roy's model. However, in other cases dissimilarities emerge. An explanation for this differences can be found by considering how the respective models account for covariance in the observations. Specifying the relevant terms using a bivariate normal distribution, Roy's model allows for both between-method and within-method covariance. \citet{BXC2008} formulate a model whereby random effects have univariate normal distribution, and no allowance is made for correlation between observations.

A consequence of this is that the between-method and within-method covariance are zero. In cases where there is negligible covariance between methods, both sets of limits of agreement are very similar to each other. In cases where there is a substantial level of covariance present between the two methods, the limits of agreement computed using models will differ.


%-----------------------------------------------------------------------------------%

\subsection{Formal testing for covariances }
As it is pertinent to the difference between the two described methodologies, the facilitation of a formal test would be useful. Extending the approach proposed by Roy, the test for overall covariance can be formulated:
\begin{eqnarray*}
	\operatorname{H_5} : \sigma_{12} = 0 \\
	\operatorname{K_5} : \sigma_{12} \neq 0
\end{eqnarray*}
As with the tests for variability, this test is performed by comparing a pair of model fits corresponding to the null and alternative hypothesis. In addition to testing the overall covariance, similar tests can be formulated for both the component variabilities if necessary.





\newpage
\bibliography{DB-txfrbib}
\end{document}


%-----------------------------------------------------------------------------------%




\begin{enumerate}
\item Univariate Normal Distribution

\[
    X\ \sim\ \mathcal{N}(\mu,\, \sigma^2),
\]

\item Bivariate Normal Distribution

\begin{itemize}
\item[(a)] \[  X\ \sim\ \mathcal{N}_2(\mu,\, \Sigma), \vspace{1cm}\]
\item[(b)] \[    \mu = \begin{pmatrix} \mu_x \\ \mu_y \end{pmatrix}, \quad
    \Sigma = \begin{pmatrix} \sigma_x^2 & \rho \sigma_x \sigma_y \\
                             \rho \sigma_x \sigma_y  & \sigma_y^2 \end{pmatrix}.\]
\end{itemize}
\end{enumerate}
\newpage




\section{Roy's Hypotheses Tests}

In order to express Roy's LME model in matrix notation we gather all $2n_i$ observations specific to item $i$ into a single vector $\boldsymbol{y}_{i} = (y_{1i1},y_{2i1},y_{1i2},\ldots,y_{mir},\ldots,y_{1in_{i}},y_{2in_{i}})^\prime.$ The LME model can be written
\[
\boldsymbol{y_{i}} = \boldsymbol{X_{i}\beta} + \boldsymbol{Z_{i}b_{i}} + \boldsymbol{\epsilon_{i}},
\]
where $\boldsymbol{\beta}=(\beta_0,\beta_1,\beta_2)^\prime$ is a vector of fixed effects, and $\boldsymbol{X}_i$ is a corresponding $2n_i\times 3$ design matrix for the fixed effects. The random effects are expressed in the vector $\boldsymbol{b}=(b_1,b_2)^\prime$, with $\boldsymbol{Z}_i$ the corresponding $2n_i\times 2$ design matrix. The vector $\boldsymbol{\epsilon}_i$ is a $2n_i\times 1$ vector of residual terms. Random effects and residuals are assumed to be independent of each other.

The random effects are assumed to be distributed as $\boldsymbol{b}_i \sim \mathcal{N}_2(0,\boldsymbol{G})$. The between-item variance covariance matrix $\boldsymbol{G}$ is constructed as follows:
\[ \boldsymbol{G} =\left(
            \begin{array}{cc}
              g^2_1  & g_{12} \\
              g_{12} & g^2_2 \\
            \end{array}
          \right) \]

The matrix of random errors $\boldsymbol{\epsilon}_i$ is distributed as $\mathcal{N}_2(0,\boldsymbol{R}_i)$.
\citet{hamlett} shows that the variance covariance matrix for the residuals(i.e. the within-item sources of variation between both methods) can be expressed as the Kroneckor product of an $n_i \times n_i$ identity matrix and the partial within-item variance covariance matrix $\boldsymbol{\Sigma}$, i.e. $\boldsymbol{R}_{i} = \boldsymbol{I}_{n_{i}} \otimes \boldsymbol{\Sigma}$.
\[
\boldsymbol{\Sigma} = \left( \begin{array}{cc}
  \sigma^2_{1} & \sigma_{12} \\
  \sigma_{12} & \sigma^2_{2} \\
\end{array}\right),
\]
where $\sigma^2_{1}$ and $\sigma^2_{2}$ are the within-subject variances of the respective methods, and $\sigma_{12}$ is the within-item covariance between the two methods. The within-item variance covariance matrix $\boldsymbol{\Sigma}$ is assumed to be the same for all replications. Computational analysis of linear mixed effects models allow for the explicit analysis of both $\boldsymbol{G}$ and $\boldsymbol{R_i}$.

For expository purposes consider the case where each item provides three replicate measurements by each method. In matrix form the model has the structure
\[
\boldsymbol{y}_{i} =
%---Design Matrix X ----%
\left(\begin{array}{ccc}
 1 & 1 & 0 \\ 1 & 0 & 1 \\ 1 & 1 & 0 \\
 1 & 0 & 1 \\ 1 & 1 & 0 \\ 1 & 0 & 1 \\
\end{array}\right)
%---FE Matrix----%
\left(\begin{array}{c}
 \beta_0 \\ \beta_1 \\ \beta_2 \\
\end{array}\right)
+
%---Design Matrix Z----%
\left(\begin{array}{cc}
1 & 0 \\0 & 1 \\1 & 0 \\0 & 1 \\0 & 1 \\\end{array}
\right)
%---RE Matrix----%
\left(\begin{array}{c}
b_{1i} \\   b_{2i} \\
\end{array}\right)
+
%------Errors Vector---%
\left( \begin{array}{c}
\epsilon_{1i1} \\\epsilon_{2i1} \\\epsilon_{1i2} \\ \epsilon_{2i2} \\\epsilon_{1i3} \\\epsilon_{2i3} \\
\end{array}\right).
\]
The between-item variance covariance $\boldsymbol{G}$ is as before, while the within-item variance covariance is given as
%------Specification of within item VC matrix R---%
\[
\boldsymbol{R}_i = \left(
\begin{array}{cc:cc:cc}
  \sigma^2_{1} & \sigma_{12} & 0 & 0 & 0 & 0 \\
  \sigma_{12} & \sigma^2_{2} & 0 & 0 & 0 & 0 \\\hdashline
  0 & 0 & \sigma^2_{1} & \sigma_{12} & 0 & 0 \\
  0 & 0 & \sigma_{12} & \sigma^2_{2} & 0 & 0 \\\hdashline
  0 & 0 & 0 & 0 & \sigma^2_{1} & \sigma_{12} \\
  0 & 0 & 0 & 0 & \sigma_{12} & \sigma^2_{2} \\
\end{array} \right)
\]

The overall variability between the two methods is the sum of between-item variability
$\boldsymbol{G}$ and partial within-item variability $\boldsymbol{\Sigma}$. \citet{roy} denotes the overall variability as ${\mbox{Block - }\boldsymbol \Omega_{i}}$. The overall variation for methods $1$ and $2$ are given by

%------Overall variability in terms of G and R ----%
\begin{equation}
\left(\begin{array}{cc}
              \omega^2_1  & \omega_{12} \\
              \omega_{12} & \omega^2_2 \\
       \end{array}  \right)
 =
\left(\begin{array}{cc}
              g^2_1  & g_{12} \\
              g_{12} & g^2_2 \\
\end{array} \right)
+
\left( \begin{array}{cc}
              \sigma^2_1  & \sigma_{12} \\
              \sigma_{12} & \sigma^2_2 \\
\end{array}\right)
\end{equation}
%------------------------------------------------------------------------%
\newpage

\end{document}
